{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "88a05bb0-aed1-474c-8cc3-72d7688ca8d2"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import random as rd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Dataset Trump Tweets\n",
    "\n",
    "On utilise l'ensemble des tweets postés par Donald Trump."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3448</th>\n",
       "      <td>Time to get out &amp;amp; caucus! @IvankaTrump, @D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1426</th>\n",
       "      <td>\"@RoxaneTancredi:  Democrats are coming to TRU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6326</th>\n",
       "      <td>\"@BOB_EWASHINGTON: @realDonaldTrump @club4grow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2342</th>\n",
       "      <td>\"@Ollie_621: @FoxNews @realDonaldTrump I think...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>About to begin a rally here in Henderson, Neva...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Tweet_Text\n",
       "3448  Time to get out &amp; caucus! @IvankaTrump, @D...\n",
       "1426  \"@RoxaneTancredi:  Democrats are coming to TRU...\n",
       "6326  \"@BOB_EWASHINGTON: @realDonaldTrump @club4grow...\n",
       "2342  \"@Ollie_621: @FoxNews @realDonaldTrump I think...\n",
       "566   About to begin a rally here in Henderson, Neva..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"trump.csv\", dtype=str, delimiter=\",\", usecols=[2])\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise les fonctions ord et chr pour facilement convertir les caractères en valeurs numériques, et on crée les ensembles d'apprentissage et de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "#TWEET_SIZE = 280\n",
    "VOCAB_SIZE = 128\n",
    "#FINAL_CHAR = 160 # espace insécable\n",
    "FINAL_CHAR = VOCAB_SIZE\n",
    " \n",
    "BLANK_OHOT = torch.FloatTensor(BATCH_SIZE, VOCAB_SIZE+1).zero_()\n",
    " \n",
    "def encode(row):\n",
    "   \n",
    "    # Conversion en int, et suppression des cractères spéciaux (emojis, bugs, etc)\n",
    "    l = [ord(c) for c in row[0] if ord(c) < VOCAB_SIZE] #[:TWEET_SIZE-1] et limitation en taille (aberrations csv)\n",
    "   \n",
    "    # Normalisation longueur tweets\n",
    "    '''\n",
    "    for i in range(len(l), TWEET_SIZE-1):\n",
    "        l.append(FINAL_CHAR)\n",
    "    l.append(FINAL_CHAR)\n",
    "    '''    \n",
    "   \n",
    "    # Ajout caractère de fin (espace insécable)\n",
    "    l.append(FINAL_CHAR)\n",
    "   \n",
    "    return l\n",
    "\n",
    "\n",
    "def decode(row):\n",
    "    return ''.join([chr(int(c)) for c in row if int(c) != FINAL_CHAR])\n",
    " \n",
    "\n",
    "def toohot(value):\n",
    "    blank = torch.FloatTensor(len(value), VOCAB_SIZE+1).zero_()\n",
    "    return blank.scatter_(1, value.view(-1, 1), 1)\n",
    " \n",
    "\n",
    "def tofint(onehot):\n",
    "    return onehot.max(-1)[1][0]\n",
    "\n",
    "\n",
    "#data_e = data.apply(encode, axis=1)\n",
    "#train = Variable(torch.Tensor(data_e[0:16000].as_matrix()))  # .view(-1, BATCH_SIZE, TWEET_SIZE)\n",
    "#test  = Variable(torch.Tensor(data_e[16000:20800].as_matrix()))  # .view(-1, BATCH_SIZE, TWEET_SIZE)\n",
    " \n",
    "dataset = [c for r in data.apply(encode, axis=1) for c in r] # Conversion et applatissement\n",
    "#dataset = dataset[:-(len(dataset)%BATCH_SIZE)]               # Coupe taille divisible en batchs entiers\n",
    "train   = torch.LongTensor(dataset[:700000])\n",
    "test    = torch.LongTensor(dataset[700000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(raw=train, length=50, index=None):\n",
    "    if index is None:\n",
    "        index = rd.randint(0, len(train))\n",
    "    return raw[index:index+length]#, raw[index+1:index+length+1]\n",
    "\n",
    "def tweet(raw=data):\n",
    "    return data.sample().iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'im or hate him, @realDonaldTrump is looking virtually unstoppable for Republican nomination.\\nMore people attack him_RT @ABCPolitics: JUST IN: Donald Trump hits 41% in new Monmouth national poll, his '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(sample(train, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Congratulations to my brother Robert &amp; Ann Marie on the success of @MontesKitchen in Dutchess County, New York (Amenia.) Great food!'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample().iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "40ed8f3e-73f1-4614-965b-1a62d18c1b84"
    }
   },
   "outputs": [],
   "source": [
    "class Recurent(nn.Module):\n",
    "    def __init__(self, tailleZ, tailleVoc, actF = nn.Sigmoid()):\n",
    "        '''X et Y vecteur onehot de taille tailleVoc\n",
    "        Z vecteur de stockage de taille tailleZ'''\n",
    "        super(Recurent, self).__init__()\n",
    "        self.XToY = nn.Linear(tailleVoc, tailleVoc)\n",
    "        self.XToZ = nn.Linear(tailleVoc, tailleZ)\n",
    "        self.ZToY = nn.Linear(tailleZ, tailleVoc)\n",
    "        self.ZToZ = nn.Linear(tailleZ, tailleZ)\n",
    "        self.actF = actF\n",
    "\n",
    "    def forward(self, x, z):\n",
    "        '''return Y, Z'''\n",
    "        #print(\"x\", x, \"z\", z)\n",
    "        return self.actF(self.XToY(x) + self.ZToY(z)), self.actF(self.XToZ(x) + self.ZToZ(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "9f3217b3-cd0a-461b-9a7d-154809350665"
    }
   },
   "outputs": [],
   "source": [
    "class RecurentGated(nn.Module):\n",
    "    def __init__(self, tailleZ, tailleVoc, actF = nn.Sigmoid()):\n",
    "        '''X et Y vecteur onehot de taille tailleVoc\n",
    "        Z vecteur de stockage de taille tailleZ'''\n",
    "        super(Recurent, self).__init__()\n",
    "        self.XToY = nn.Linear(tailleVoc, tailleVoc)\n",
    "        self.XToZ = nn.Linear(tailleVoc, tailleZ)\n",
    "        self.ZToY = nn.Linear(tailleZ, tailleVoc)\n",
    "        self.ZToZ = nn.Linear(tailleZ, tailleZ)\n",
    "        self.gateZ = nn.Linear(tailleVoc, tailleZ)\n",
    "        self.gateY = nn.Linear(tailleVoc, tailleVoc)\n",
    "        self.actF = actF\n",
    "\n",
    "    def forward(self, x, z):\n",
    "        '''return Z, Y'''\n",
    "        soft = torch.nn.Softmax(-1)\n",
    "        return soft(self.XtoZ(x)) * self.actF(self.gateZ(x)) + self.actF(self.ZtoZ(z)) * (1-self.actF(self.gateZ(x))),\\\n",
    "    self.actF(self.XtoY(x)) * self.actF(self.gateY(x)) + self.actF(self.ZtoY(z)) + (1 - self.actF(self.gateY(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "b626bc25-a3b4-439b-9061-93af485b008b"
    }
   },
   "outputs": [],
   "source": [
    "class RNNMono(object):\n",
    "    def __init__(self, recur, stop):\n",
    "        super(RNNMono, self).__init__()\n",
    "        self.recur = recur\n",
    "        self.stop = stop\n",
    "        self.losses = []\n",
    "    \n",
    "    def predict(self, boot, z):\n",
    "        for i in boot:\n",
    "            z, x = self.recur(i,z)\n",
    "        r = []\n",
    "        r.append(x)\n",
    "        while (x.max(-1)[1].data != self.stop.max(-1)[1]).all() :\n",
    "            z, x = self.recur(x,z)\n",
    "            #print(voc.inverse[x.max(-1)[1].data[-1]])\n",
    "            r.append(x)\n",
    "        return r, z\n",
    "    \n",
    "    def train(self, inputs, z):\n",
    "        '''\n",
    "            :param inputs: Input sequence\n",
    "        '''\n",
    "        loss = nn.MSELoss()\n",
    "        sgd  = optim.SGD(self.recur.parameters(), lr=1e-3)\n",
    "        \n",
    "        i = Variable(BLANK_OHOT)\n",
    "        r, z = self.recur(i, z)\n",
    "        \n",
    "        for i in inputs:\n",
    "            i = i.view(1, 129)\n",
    "            loss = loss.forward(i, r)\n",
    "            loss.backward()\n",
    "            self.losses.append(loss)\n",
    "            sgd.step()\n",
    "            \n",
    "            r, z = self.recur(i, z)\n",
    "        \n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "nn criterions don't compute the gradient w.r.t. targets - please mark these variables as volatile or not requiring gradients",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-69f61afed72a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzLen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-48-d3f8006ecf9f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, inputs, z)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m129\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/anti/.anaconda3/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \"\"\"\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0m_assert_no_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/anti/.anaconda3/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36m_assert_no_grad\u001b[0;34m(variable)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_assert_no_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;34m\"nn criterions don't compute the gradient w.r.t. targets - please \"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;34m\"mark these variables as volatile or not requiring gradients\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: nn criterions don't compute the gradient w.r.t. targets - please mark these variables as volatile or not requiring gradients"
     ]
    }
   ],
   "source": [
    "zLen = 1000\n",
    "recur = Recurent(zLen, VOCAB_SIZE+1)\n",
    "m = RNNMono(recur, toohot(torch.LongTensor([FINAL_CHAR])))\n",
    "TRAIN_ITER = 500\n",
    "\n",
    "lossHisto = []\n",
    "scoreHisto = []\n",
    "\n",
    "for i in range(TRAIN_ITER):\n",
    "    \n",
    "    if i%(TRAIN_ITER/10) == 0:\n",
    "        print(\"Iteration\", i)\n",
    "    \n",
    "    x = Variable(toohot(torch.LongTensor(encode(tweet()))))\n",
    "    z = Variable(torch.zeros(zLen).type(torch.FloatTensor))\n",
    "    \n",
    "    f,_ = m.train(x, z)\n",
    "    print(f, y)\n",
    "    loss = ml.forward(f, y).backward()\n",
    "    opt.step()\n",
    "    \n",
    "    lossHisto.append(loss.data.mean())\n",
    "    ypred = torch.max(f, 1)[1]\n",
    "    scoreHisto.append(torch.eq(ypred.data, yN).float().mean())\n",
    "    \n",
    "plt.plot(lossHisto)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('nb batch traited')\n",
    "plt.show()\n",
    "plt.plot(scoreHisto)\n",
    "plt.ylabel('score')\n",
    "plt.xlabel('nb batch traited')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "class RNNMono(nn.Module):\n",
    "    def __init__(self, recur, stop):\n",
    "        super(RNNMono, self).__init__()\n",
    "        self.recur = recur\n",
    "        self.stop = stop\n",
    "    \n",
    "    def forward(self, boot, z):\n",
    "        for i in boot:\n",
    "            z, x = self.recur(i,z)\n",
    "        x = x.max(0)[1]\n",
    "        x = x.unsqueeze(-1).scatter(-1, x, 1.)\n",
    "        r = x.unsqueeze(0)\n",
    "        while (x != self.stop).all() :\n",
    "            z, x = self.recur(x,z)\n",
    "            '''xm = x.max(0)[1]\n",
    "            x_onehot = torch.FloatTensor(*xm.size(), x.size()[0]).zero_()\n",
    "            x_onehot.scatter_(1, torch.unsqueeze(xm.data, 1), 1.)\n",
    "            x = x_onehot'''\n",
    "            x = x.max(0)[1]\n",
    "            x = x.unsqueeze(-1).scatter_(-1, x, 1.)\n",
    "            r.cat(x.unsqueeze_(-1),0)\n",
    "        return r, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "13c683a1-4314-4f4b-ba89-9595c02e7205"
    }
   },
   "outputs": [],
   "source": [
    "def sequencer(x, end):\n",
    "    r = []\n",
    "    for i in x :\n",
    "        r.append(i)\n",
    "        if i == end :\n",
    "            yield r\n",
    "            r = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "nbpresent": {
     "id": "26de8649-3e8a-4a05-baad-d2ef655bafd3"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dave aneckstein4 simmons research4 an ezperian company they have not been charged or formally arrested5 iran isnt making an atomic bomb4 not at all4 chave.\n",
      " said monday5 the japanesemade tin robots have blocky heads and moveable arms and legs5 if they could no longer be the nominees4 then they would be pundits of the first order men with credibility on oval office matters by dint of once sitting in the chair themselves5 free challenge kits have a cd and brochure from dr5 ian4 menu and fitness advice and a pedometer to count steps5 the world motor sport council received statements from fernando alonso4 lewis hamilton and pedro de la rosa stating categorically no ferrari information had been used by mclaren4 and that no confidential data had been passed to the team5 the prime minister said the first citi.\n"
     ]
    }
   ],
   "source": [
    "for i in sequencer(ten[:1000], 35):\n",
    "    print(code2char(i, voc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "0f3b34d4-3d05-4851-b49d-e71603744639"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "zLen = 1000\n",
    "vocLen = 36\n",
    "recur = Recurent(zLen, vocLen)\n",
    "\n",
    "endN = torch.LongTensor([vocLen-1])\n",
    "end_onehot = torch.FloatTensor(*endN.size(), vocLen).zero_()\n",
    "end_onehot.scatter_(1, torch.unsqueeze(endN, 1), 1.)\n",
    "\n",
    "m = RNNMono(recur, end_onehot)\n",
    "ml = nn.MSELoss()\n",
    "ite = 500\n",
    "opt = optim.SGD(m.parameters(), lr=1e-3)\n",
    "\n",
    "lossHisto = []\n",
    "scoreHisto = []\n",
    "\n",
    "for i,seq in enumerate(sequencer(ten, 35)):\n",
    "    if i > ite :\n",
    "        break\n",
    "    if i%(ite/10) == 0:\n",
    "        print(\"Iteration\", i)\n",
    "    \n",
    "    xN = torch.LongTensor(seq[:30])\n",
    "    x_onehot = torch.FloatTensor(*xN.size(), vocLen).zero_()\n",
    "    x_onehot.scatter_(1, torch.unsqueeze(xN, 1), 1.)\n",
    "    x = autograd.Variable(x_onehot.type(torch.FloatTensor))\n",
    "    \n",
    "    yN = torch.LongTensor(seq[30:])\n",
    "    y_onehot = torch.FloatTensor(*yN.size(), vocLen).zero_()\n",
    "    y_onehot.scatter_(1, torch.unsqueeze(yN, 1), 1.)\n",
    "    y = autograd.Variable(y_onehot.type(torch.FloatTensor))\n",
    "    \n",
    "    z = autograd.Variable(torch.zeros(zLen).type(torch.FloatTensor))\n",
    "    \n",
    "    f,_ = m.forward(x, z)\n",
    "    print(f, y)\n",
    "    loss = ml.forward(f, y)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    \n",
    "    lossHisto.append(loss.data.mean())\n",
    "    ypred = torch.max(f, 1)[1]\n",
    "    scoreHisto.append(torch.eq(ypred.data, yN).float().mean())\n",
    "    \n",
    "plt.plot(lossHisto)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('nb batch traited')\n",
    "plt.show()\n",
    "plt.plot(scoreHisto)\n",
    "plt.ylabel('score')\n",
    "plt.xlabel('nb batch traited')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "44b57bc0-5a12-4da5-a879-305849b19a34"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
