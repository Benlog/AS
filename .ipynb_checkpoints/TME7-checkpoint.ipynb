{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbpresent": {
     "id": "88a05bb0-aed1-474c-8cc3-72d7688ca8d2"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import random as rd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Dataset Trump Tweets\n",
    "\n",
    "On utilise l'ensemble des tweets postés par Donald Trump."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5053</th>\n",
       "      <td>\"@marklindsay78: @Hanan_Khan2 @realDonaldTrump...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>Will be on @OreillyFactor tonight at 8:30pm @F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4183</th>\n",
       "      <td>#TheRemembranceProject\\nhttps://t.co/zMW0mkkFE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>\"@bigdog_joey: @realDonaldTrump @timkaine is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4505</th>\n",
       "      <td>Heading to Manassas, Virginia, for a rally. Wi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Tweet_Text\n",
       "5053  \"@marklindsay78: @Hanan_Khan2 @realDonaldTrump...\n",
       "1428  Will be on @OreillyFactor tonight at 8:30pm @F...\n",
       "4183  #TheRemembranceProject\\nhttps://t.co/zMW0mkkFE...\n",
       "608   \"@bigdog_joey: @realDonaldTrump @timkaine is s...\n",
       "4505  Heading to Manassas, Virginia, for a rally. Wi..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"trump.csv\", dtype=str, delimiter=\",\", usecols=[2])\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise les fonctions ord et chr pour facilement convertir les caractères en valeurs numériques, et on crée les ensembles d'apprentissage et de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "#TWEET_SIZE = 280\n",
    "VOCAB_SIZE = 128\n",
    "#FINAL_CHAR = 160 # espace insécable\n",
    "FINAL_CHAR = VOCAB_SIZE\n",
    " \n",
    "BLANK_OHOT = torch.FloatTensor(BATCH_SIZE, VOCAB_SIZE+1).zero_()\n",
    " \n",
    "def encode(row):\n",
    "   \n",
    "    # Conversion en int, et suppression des cractères spéciaux (emojis, bugs, etc)\n",
    "    #[:TWEET_SIZE-1] et limitation en taille (aberrations csv)\n",
    "   \n",
    "    # Normalisation longueur tweets\n",
    "    '''\n",
    "    for i in range(len(l), TWEET_SIZE-1):\n",
    "        l.append(FINAL_CHAR)\n",
    "    l.append(FINAL_CHAR)\n",
    "    '''    \n",
    "    # Ajout caractère de fin (espace insécable)\n",
    "   \n",
    "    return [ord(c) for c in row if ord(c) < VOCAB_SIZE] + [FINAL_CHAR]\n",
    "\n",
    "\n",
    "def decode(row):\n",
    "    return ''.join([chr(int(c)) for c in row if int(c) != FINAL_CHAR])\n",
    " \n",
    "\n",
    "def toohot(value):\n",
    "    blank = torch.FloatTensor(len(value), VOCAB_SIZE+1).zero_()\n",
    "    return blank.scatter_(1, value.view(-1, 1), 1)\n",
    " \n",
    "\n",
    "def tofint(onehot):\n",
    "    return onehot.max(-1)[1]\n",
    "\n",
    "\n",
    "#data_e = data.apply(encode, axis=1)\n",
    "#train = Variable(torch.Tensor(data_e[0:16000].as_matrix()))  # .view(-1, BATCH_SIZE, TWEET_SIZE)\n",
    "#test  = Variable(torch.Tensor(data_e[16000:20800].as_matrix()))  # .view(-1, BATCH_SIZE, TWEET_SIZE)\n",
    " \n",
    "#dataset = [c for r in data.apply(encode, axis=1) for c in r] # Conversion et applatissement\n",
    "#dataset = dataset[:-(len(dataset)%BATCH_SIZE)]               # Coupe taille divisible en batchs entiers\n",
    "#train   = torch.LongTensor(dataset[:700000])\n",
    "#test    = torch.LongTensor(dataset[700000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def sample(raw=train, length=50, index=None):\n",
    "#    if index is None:\n",
    "#        index = rd.randint(0, len(raw))\n",
    "#    return raw[index:index+length]#, raw[index+1:index+length+1]\n",
    "\n",
    "def tweet(raw=data):\n",
    "    return data.sample().iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decode(sample(data, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"@about_life: @realDonaldTrump Silent Warriors 4 Trump 2016 - Vets! Let۪s Take America Back! - silentwarriors4trump2016@gmail.com\"'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample().iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbpresent": {
     "id": "40ed8f3e-73f1-4614-965b-1a62d18c1b84"
    }
   },
   "outputs": [],
   "source": [
    "class Recurent(nn.Module):\n",
    "    def __init__(self, tailleZ, tailleVoc, actF = nn.Sigmoid()):\n",
    "        '''X et Y vecteur onehot de taille tailleVoc\n",
    "        Z vecteur de stockage de taille tailleZ'''\n",
    "        super(Recurent, self).__init__()\n",
    "        self.XToY = nn.Linear(tailleVoc, tailleVoc)\n",
    "        self.XToZ = nn.Linear(tailleVoc, tailleZ)\n",
    "        self.ZToY = nn.Linear(tailleZ, tailleVoc)\n",
    "        self.ZToZ = nn.Linear(tailleZ, tailleZ)\n",
    "        self.actF = actF\n",
    "\n",
    "    def forward(self, x, z):\n",
    "        '''return Y, Z'''\n",
    "        return self.actF(self.XToY(x) + self.ZToY(z)), self.actF(self.XToZ(x) + self.ZToZ(z))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "nbpresent": {
     "id": "9f3217b3-cd0a-461b-9a7d-154809350665"
    }
   },
   "source": [
    "class RecurentGated(nn.Module):\n",
    "    def __init__(self, tailleZ, tailleVoc, actF = nn.Sigmoid()):\n",
    "        '''X et Y vecteur onehot de taille tailleVoc\n",
    "        Z vecteur de stockage de taille tailleZ'''\n",
    "        super(Recurent, self).__init__()\n",
    "        self.XToY = nn.Linear(tailleVoc, tailleVoc)\n",
    "        self.XToZ = nn.Linear(tailleVoc, tailleZ)\n",
    "        self.ZToY = nn.Linear(tailleZ, tailleVoc)\n",
    "        self.ZToZ = nn.Linear(tailleZ, tailleZ)\n",
    "        self.gateZ = nn.Linear(tailleVoc, tailleZ)\n",
    "        self.gateY = nn.Linear(tailleVoc, tailleVoc)\n",
    "        self.actF = actF\n",
    "\n",
    "    def forward(self, x, z):\n",
    "        '''return Z, Y'''\n",
    "        soft = torch.nn.Softmax(-1)\n",
    "        return soft(self.XtoZ(x)) * self.actF(self.gateZ(x)) + self.actF(self.ZtoZ(z)) * (1-self.actF(self.gateZ(x))),\\\n",
    "    self.actF(self.XtoY(x)) * self.actF(self.gateY(x)) + self.actF(self.ZtoY(z)) + (1 - self.actF(self.gateY(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "b626bc25-a3b4-439b-9061-93af485b008b"
    }
   },
   "outputs": [],
   "source": [
    "class RNNMono(object):\n",
    "    def __init__(self, recur, stop, maxLen = 100, debug = False):\n",
    "        super(RNNMono, self).__init__()\n",
    "        self.recur = recur\n",
    "        self.stop = stop\n",
    "        self.maxLen = maxLen\n",
    "        self.debug = debug\n",
    "        if self.debug :\n",
    "            self.lossHisto = []\n",
    "            self.diffHisto = []\n",
    "    \n",
    "    def predict(self, boot, z):\n",
    "        for i in boot:\n",
    "            x, z = self.recur(i,z)\n",
    "        r = []\n",
    "        r.append(x)\n",
    "        cpt = 0\n",
    "        while tofint(x.data)[0] != tofint(self.stop)[0] and cpt <= self.maxLen:\n",
    "            cpt +=1\n",
    "            x, z = self.recur(x,z)\n",
    "            r.append(x)\n",
    "        \n",
    "        r = torch.stack(r)\n",
    "        return r, z\n",
    "    \n",
    "    def train(self, inputs, z):\n",
    "        '''\n",
    "            :param inputs: Input sequence\n",
    "        '''\n",
    "        loss = nn.MSELoss()\n",
    "        sgd  = optim.SGD(self.recur.parameters(), lr=1e-3)\n",
    "        \n",
    "        i = Variable(BLANK_OHOT)\n",
    "        r, z = self.recur(i, z)\n",
    "        l = loss.forward(r, inputs[0])\n",
    "        if self.debug : self.lossHisto.append(l.data.mean())\n",
    "        if self.debug : self.diffHisto.append((decode(tofint(inputs[0])), decode(tofint(r)), l.data.mean()))\n",
    "        \n",
    "        for i in inputs[:]:\n",
    "            #print(decode(tofint(i)))\n",
    "            #i = i.view(1, 129)\n",
    "            r, z = self.recur(i, z)\n",
    "            l += loss.forward(r, i)\n",
    "            if self.debug : self.lossHisto.append(l.data.mean())\n",
    "            if self.debug : self.diffHisto.append((decode(tofint(i)), decode(tofint(r)), l.data.mean()))\n",
    "                \n",
    "        l.backward()   \n",
    "        sgd.step()\n",
    "        \n",
    "        return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On teste d'abord avec du onehot, un loss mse et une prédiction en max."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zLen = 1000\n",
    "recur = Recurent(zLen, VOCAB_SIZE+1)\n",
    "m = RNNMono(recur, toohot(torch.LongTensor([FINAL_CHAR])), debug = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_ITER = 1000\n",
    "lossHisto = []\n",
    "diffHisto = []\n",
    "for i in range(TRAIN_ITER):\n",
    "    \n",
    "    if i%(TRAIN_ITER/10) == 0:\n",
    "        print(\"Iteration\", i)\n",
    "    \n",
    "    t = tweet()\n",
    "    #print(t)\n",
    "    x = Variable(toohot(torch.LongTensor(encode(t))))\n",
    "    z = Variable(torch.zeros(zLen).type(torch.FloatTensor))\n",
    "    m.train(x, z)\n",
    "\n",
    "plt.plot(m.lossHisto)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('nb batch traited')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m.diffHisto[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tweet()\n",
    "tCut = t[:10]\n",
    "te = Variable(toohot(torch.LongTensor(encode(tCut))), volatile = True)\n",
    "z = Variable(torch.zeros(zLen).type(torch.FloatTensor), volatile = True)\n",
    "r, z = m.predict(te, z)\n",
    "print(t)\n",
    "print(tCut)\n",
    "print(tofint(r))\n",
    "print(decode(tofint(r)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle est trop mauvais pour apprendre ces tweet, testons avec des données plus simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zLen = 1000\n",
    "recur = Recurent(zLen, VOCAB_SIZE+1)\n",
    "m = RNNMono(recur, toohot(torch.LongTensor([FINAL_CHAR])), debug = True)\n",
    "TRAIN_ITER = 1000\n",
    "for i in range(TRAIN_ITER):\n",
    "    \n",
    "    if i%(TRAIN_ITER/10) == 0:\n",
    "        print(\"Iteration\", i)\n",
    "    \n",
    "    t = 'test'\n",
    "    #print(t)\n",
    "    x = Variable(toohot(torch.LongTensor(encode(t))))\n",
    "    z = Variable(torch.zeros(zLen).type(torch.FloatTensor))\n",
    "    m.train(x, z)\n",
    "\n",
    "plt.plot(m.lossHisto)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('nb batch traited')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m.diffHisto[-100:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle apprend tant bien que mal le mot, ça veut dire qu'il peut apprendre mais est trop mauvais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, tailleZ, tailleVoc, actF = nn.Sigmoid()):\n",
    "        '''X et Y vecteur onehot de taille tailleVoc\n",
    "        Z vecteur de stockage de taille tailleZ'''\n",
    "        super(Encoder, self).__init__()\n",
    "        self.XToZ = nn.Linear(tailleVoc, tailleZ)\n",
    "        self.ZToZ = nn.Linear(tailleZ, tailleZ)\n",
    "        self.actF = actF\n",
    "\n",
    "    def forward(self, x, z):\n",
    "        '''return Z'''\n",
    "        return self.actF(self.XToZ(x) + self.ZToZ(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(object):\n",
    "    def __init__(self, recurIn, recurOut, stop, maxLen = 100, debug = False):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.recurIn = recurIn\n",
    "        self.recurOut = recurOut\n",
    "        self.stop = stop\n",
    "        self.maxLen = maxLen\n",
    "        self.debug = debug\n",
    "        if self.debug :\n",
    "            self.lossHisto = []\n",
    "            self.diffHisto = []\n",
    "    \n",
    "    def predict(self, boot, z):\n",
    "        for i in boot:\n",
    "            z = self.recurIn(i,z)\n",
    "        r = []\n",
    "        cpt = 1\n",
    "        x, z = self.recurOut(boot[-1],z)\n",
    "        r.append(x)\n",
    "        while tofint(x.data)[0] != tofint(self.stop)[0] and cpt <= self.maxLen:\n",
    "            cpt +=1\n",
    "            x, z = self.recurOut(x,z)\n",
    "            r.append(x)\n",
    "        \n",
    "        r = torch.stack(r)\n",
    "        return r, z\n",
    "    \n",
    "    def train(self, inputs, z, outputs):\n",
    "        '''\n",
    "            :param inputs: Input sequence\n",
    "        '''\n",
    "        loss = nn.MSELoss()\n",
    "        sgdIn  = optim.SGD(self.recurIn.parameters(), lr=1e-3)\n",
    "        sgdOut  = optim.SGD(self.recurOut.parameters(), lr=1e-3)\n",
    "        \n",
    "        for i in inputs[:-1]:\n",
    "            #print(decode(tofint(i)))\n",
    "            #i = i.view(1, 129)\n",
    "            z = self.recurIn(i, z)\n",
    "            \n",
    "        r = inputs[-1]\n",
    "        l = 0\n",
    "        for i in outputs:\n",
    "            r, z = self.recurOut(r, z)\n",
    "            l += loss.forward(r, i)\n",
    "            if self.debug : self.lossHisto.append(l.data.mean())\n",
    "            if self.debug : self.diffHisto.append((decode(tofint(i)), decode(tofint(r)), l.data.mean()))\n",
    "                \n",
    "        l.backward()   \n",
    "        sgdIn.step()\n",
    "        sgdOut.step()\n",
    "        \n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zLen = 1000\n",
    "recurIn = Encoder(zLen, VOCAB_SIZE+1)\n",
    "recurOut = Recurent(zLen, VOCAB_SIZE+1)\n",
    "m = Seq2Seq(recurIn, recurOut, toohot(torch.LongTensor([FINAL_CHAR])), debug = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_ITER = 1000\n",
    "lossHisto = []\n",
    "diffHisto = []\n",
    "for i in range(TRAIN_ITER):\n",
    "    \n",
    "    if i%(TRAIN_ITER/10) == 0:\n",
    "        print(\"Iteration\", i)\n",
    "    \n",
    "    t = tweet()\n",
    "    #print(t)\n",
    "    x = Variable(toohot(torch.LongTensor(encode(t[:10]))))\n",
    "    y = Variable(toohot(torch.LongTensor(encode(t[10:]))))\n",
    "    z = Variable(torch.zeros(zLen).type(torch.FloatTensor))\n",
    "    m.train(x, z, y)\n",
    "\n",
    "plt.plot(m.lossHisto)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('nb batch traited')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m.diffHisto[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tweet()\n",
    "tCut = t[:10]\n",
    "te = Variable(toohot(torch.LongTensor(encode(tCut))), volatile = True)\n",
    "z = Variable(torch.zeros(zLen).type(torch.FloatTensor), volatile = True)\n",
    "r, z = m.predict(te, z)\n",
    "print(t)\n",
    "print(tCut)\n",
    "print(tofint(r))\n",
    "print(decode(tofint(r)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les résultats sont toujours aussi mauvais, on va donc tenter avec un loss différent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "nbpresent": {
     "id": "40ed8f3e-73f1-4614-965b-1a62d18c1b84"
    }
   },
   "outputs": [],
   "source": [
    "class Recurent(nn.Module):\n",
    "    def __init__(self, tailleZ, tailleVoc, actFZ = nn.Sigmoid(), actFY = nn.Sigmoid()):\n",
    "        #nn.LogSoftmax(dim=-1)\n",
    "        '''X et Y vecteur onehot de taille tailleVoc\n",
    "        Z vecteur de stockage de taille tailleZ'''\n",
    "        super(Recurent, self).__init__()\n",
    "        self.XToY = nn.Linear(tailleVoc, tailleVoc)\n",
    "        self.XToZ = nn.Linear(tailleVoc, tailleZ)\n",
    "        self.ZToY = nn.Linear(tailleZ, tailleVoc)\n",
    "        self.ZToZ = nn.Linear(tailleZ, tailleZ)\n",
    "        self.actFZ = actFZ\n",
    "        self.actFY = actFY\n",
    "\n",
    "    def forward(self, x, z):\n",
    "        '''return Y, Z'''\n",
    "        return self.actFY(self.XToY(x) + self.ZToY(z)), self.actFZ(self.XToZ(x) + self.ZToZ(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, tailleZ, tailleVoc, actF = nn.Sigmoid()):\n",
    "        '''X et Y vecteur onehot de taille tailleVoc\n",
    "        Z vecteur de stockage de taille tailleZ'''\n",
    "        super(Encoder, self).__init__()\n",
    "        self.XToZ = nn.Linear(tailleVoc, tailleZ)\n",
    "        self.ZToZ = nn.Linear(tailleZ, tailleZ)\n",
    "        self.actF = actF\n",
    "\n",
    "    def forward(self, x, z):\n",
    "        '''return Z'''\n",
    "        return self.actF(self.XToZ(x) + self.ZToZ(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(object):\n",
    "    def __init__(self, recurIn, recurOut, stop, maxLen = 100, debug = False):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.recurIn = recurIn\n",
    "        self.recurOut = recurOut\n",
    "        self.stop = stop\n",
    "        self.maxLen = maxLen\n",
    "        self.debug = debug\n",
    "        if self.debug :\n",
    "            self.lossHisto = []\n",
    "            self.diffHisto = []\n",
    "    \n",
    "    def predict(self, boot, z):\n",
    "        for i in boot:\n",
    "            z = self.recurIn(i,z)\n",
    "        r = []\n",
    "        cpt = 1\n",
    "        x, z = self.recurOut(boot[-1],z)\n",
    "        r.append(x)\n",
    "        while tofint(x.data)[0] != tofint(self.stop)[0] and cpt <= self.maxLen:\n",
    "            cpt +=1\n",
    "            x, z = self.recurOut(x,z)\n",
    "            r.append(x)\n",
    "        \n",
    "        r = torch.stack(r)\n",
    "        return r, z\n",
    "    \n",
    "    def train(self, inputs, z, outputs):\n",
    "        '''\n",
    "            :param inputs: Input sequence\n",
    "        '''\n",
    "        loss = nn.CrossEntropyLoss()\n",
    "        sgdIn  = optim.SGD(self.recurIn.parameters(), lr=1e-3)\n",
    "        sgdOut  = optim.SGD(self.recurOut.parameters(), lr=1e-3)\n",
    "        \n",
    "        for i in inputs[:-1]:\n",
    "            z = self.recurIn(i, z)\n",
    "            \n",
    "        r = inputs[-1]\n",
    "        l = 0\n",
    "        for i in outputs:\n",
    "            r, z = self.recurOut(r, z)\n",
    "            l += loss.forward(r.unsqueeze(0), i)\n",
    "            if self.debug : self.diffHisto.append((decode(i), decode(tofint(r)), l.data.mean()))\n",
    "        \n",
    "        if self.debug : self.lossHisto.append(l.data.mean())        \n",
    "        l.backward()   \n",
    "        sgdIn.step()\n",
    "        sgdOut.step()\n",
    "        \n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "zLen = 1000\n",
    "recurIn = Encoder(zLen, VOCAB_SIZE+1)\n",
    "recurOut = Recurent(zLen, VOCAB_SIZE+1)\n",
    "m = Seq2Seq(recurIn, recurOut, toohot(torch.LongTensor([FINAL_CHAR])), debug = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Iteration 100\n",
      "Iteration 200\n",
      "Iteration 300\n",
      "Iteration 400\n",
      "Iteration 500\n",
      "Iteration 600\n",
      "Iteration 700\n",
      "Iteration 800\n",
      "Iteration 900\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb772fb4b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TRAIN_ITER = 1000\n",
    "lossHisto = []\n",
    "diffHisto = []\n",
    "for i in range(TRAIN_ITER):\n",
    "    \n",
    "    if i%(TRAIN_ITER/10) == 0:\n",
    "        print(\"Iteration\", i)\n",
    "    \n",
    "    t = tweet()\n",
    "    #print(t)\n",
    "    \n",
    "    x = Variable(toohot(torch.LongTensor(encode(t[:10]))))\n",
    "    y = Variable(torch.LongTensor(encode(t[10:])))\n",
    "    z = Variable(torch.zeros(zLen).type(torch.FloatTensor))\n",
    "    m.train(x, z, y)\n",
    "\n",
    "plt.plot(m.lossHisto)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('nb batch traited')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' ', 'w', 4.808780193328857),\n",
       " ('#', 'K', 9.587392807006836),\n",
       " ('I', 'K', 14.511201858520508),\n",
       " ('A', 'K', 19.490232467651367),\n",
       " ('C', 'K', 24.161285400390625),\n",
       " ('a', 'K', 29.236421585083008),\n",
       " ('u', 'K', 33.96312713623047),\n",
       " ('c', 'K', 38.843048095703125),\n",
       " ('u', 'K', 43.56975173950195),\n",
       " ('s', 'K', 48.36529541015625),\n",
       " (' ', 'K', 53.118560791015625),\n",
       " ('F', 'K', 57.997825622558594),\n",
       " ('i', 'K', 62.74555587768555),\n",
       " ('n', 'K', 67.69074249267578),\n",
       " ('d', 'K', 72.44332885742188),\n",
       " ('e', 'K', 77.41819763183594),\n",
       " ('r', 'K', 82.25212097167969),\n",
       " (':', 'K', 87.16873931884766),\n",
       " ('\\n', 'K', 91.99395751953125),\n",
       " ('h', 'K', 96.8084945678711),\n",
       " ('t', 'K', 101.60860443115234),\n",
       " ('t', 'K', 106.4087142944336),\n",
       " ('p', 'K', 111.20709991455078),\n",
       " ('s', 'K', 116.00263977050781),\n",
       " (':', 'K', 120.91925811767578),\n",
       " ('/', 'K', 125.78880310058594),\n",
       " ('/', 'K', 130.65835571289062),\n",
       " ('t', 'K', 135.45846557617188),\n",
       " ('.', 'K', 140.3627471923828),\n",
       " ('c', 'K', 145.24267578125),\n",
       " ('o', 'K', 149.9824981689453),\n",
       " ('/', 'K', 154.85205078125),\n",
       " ('A', 'K', 159.83084106445312),\n",
       " ('N', 'K', 164.62464904785156),\n",
       " ('v', 'K', 169.47364807128906),\n",
       " ('T', 'K', 174.1847686767578),\n",
       " ('c', 'K', 179.064697265625),\n",
       " ('Z', 'K', 183.7617950439453),\n",
       " ('q', 'K', 188.52999877929688),\n",
       " ('f', 'K', 193.4964599609375),\n",
       " ('O', 'K', 198.2124481201172),\n",
       " ('q', 'K', 202.98065185546875),\n",
       " (' ', 'K', 207.73391723632812),\n",
       " ('h', 'K', 212.54844665527344),\n",
       " ('t', 'K', 217.3485565185547),\n",
       " ('t', 'K', 222.14866638183594),\n",
       " ('p', 'K', 226.94705200195312),\n",
       " ('s', 'K', 231.7425994873047),\n",
       " (':', 'K', 236.65921020507812),\n",
       " ('/', 'K', 241.52874755859375),\n",
       " ('/', 'K', 246.39828491210938),\n",
       " ('t', 'K', 251.19839477539062),\n",
       " ('.', 'K', 256.1026916503906),\n",
       " ('c', 'K', 260.98260498046875),\n",
       " ('o', 'K', 265.722412109375),\n",
       " ('/', 'K', 270.5919494628906),\n",
       " ('1', 'K', 275.5130310058594),\n",
       " ('v', 'K', 280.3620300292969),\n",
       " ('j', 'K', 285.2257995605469),\n",
       " ('C', 'K', 289.89678955078125),\n",
       " ('H', 'K', 294.8302917480469),\n",
       " ('Y', 'K', 299.6141357421875),\n",
       " ('Y', 'K', 304.3979797363281),\n",
       " ('l', 'K', 309.3222961425781),\n",
       " ('z', 'K', 314.215087890625),\n",
       " ('U', 'K', 319.1261291503906),\n",
       " ('', 'K', 323.90350341796875),\n",
       " ('v', 't', 4.775448799133301),\n",
       " ('e', 'K', 9.724924087524414),\n",
       " ('r', 'K', 14.545537948608398),\n",
       " ('y', 'K', 19.593441009521484),\n",
       " (' ', 'K', 24.310081481933594),\n",
       " ('d', 'K', 29.057626724243164),\n",
       " ('i', 'K', 33.79971694946289),\n",
       " ('s', 'K', 38.54771423339844),\n",
       " ('l', 'K', 43.460777282714844),\n",
       " ('o', 'K', 48.18145751953125),\n",
       " ('y', 'K', 53.22871017456055),\n",
       " ('a', 'K', 58.29084014892578),\n",
       " ('l', 'K', 63.20390319824219),\n",
       " (' ', 'K', 67.92041015625),\n",
       " ('t', 'K', 72.62782287597656),\n",
       " ('o', 'K', 77.34850311279297),\n",
       " (' ', 'K', 82.06501007080078),\n",
       " ('B', 'K', 87.03736877441406),\n",
       " ('u', 'K', 91.74005889892578),\n",
       " ('s', 'K', 96.48805236816406),\n",
       " ('h', 'K', 101.27320098876953),\n",
       " (',', 'K', 106.19989776611328),\n",
       " (' ', 'K', 110.9164047241211),\n",
       " ('h', 'K', 115.70155334472656),\n",
       " ('i', 'K', 120.44364929199219),\n",
       " ('s', 'K', 125.19164276123047),\n",
       " (' ', 'K', 129.90814208984375),\n",
       " ('m', 'K', 134.84251403808594),\n",
       " ('e', 'K', 139.79983520507812),\n",
       " ('n', 'K', 144.73219299316406),\n",
       " ('t', 'K', 149.43960571289062),\n",
       " ('o', 'K', 154.16029357910156),\n",
       " ('r', 'K', 158.9864959716797),\n",
       " (',', 'K', 163.91319274902344),\n",
       " (' ', 'K', 168.62969970703125),\n",
       " ('w', 'K', 173.45545959472656),\n",
       " ('h', 'K', 178.2406005859375),\n",
       " ('e', 'K', 183.1979217529297),\n",
       " ('n', 'K', 188.13027954101562),\n",
       " (' ', 'K', 192.84678649902344),\n",
       " ('h', 'K', 197.63192749023438),\n",
       " ('e', 'K', 202.58924865722656),\n",
       " (' ', 'K', 207.30575561523438),\n",
       " ('d', 'K', 212.05331420898438),\n",
       " ('e', 'K', 217.01063537597656),\n",
       " ('c', 'K', 221.82569885253906),\n",
       " ('i', 'K', 226.5677947998047),\n",
       " ('d', 'K', 231.3153533935547),\n",
       " ('e', 'K', 236.27267456054688),\n",
       " ('d', 'K', 241.02023315429688),\n",
       " (' ', 'K', 245.7367401123047),\n",
       " ('t', 'K', 250.44415283203125),\n",
       " ('o', 'K', 255.1648406982422),\n",
       " (' ', 'K', 259.88134765625),\n",
       " ('r', 'K', 264.7075500488281),\n",
       " ('u', 'K', 269.4102478027344),\n",
       " ('n', 'K', 274.34259033203125),\n",
       " (' ', 'K', 279.05908203125),\n",
       " ('a', 'K', 284.1212158203125),\n",
       " ('g', 'K', 288.9423828125),\n",
       " ('a', 'K', 294.0045166015625),\n",
       " ('i', 'K', 298.7466125488281),\n",
       " ('n', 'K', 303.678955078125),\n",
       " ('s', 'K', 308.42694091796875),\n",
       " ('t', 'K', 313.13433837890625),\n",
       " (' ', 'K', 317.850830078125),\n",
       " ('h', 'K', 322.635986328125),\n",
       " ('i', 'K', 327.3780822753906),\n",
       " ('m', 'K', 332.3124694824219),\n",
       " ('.', 'K', 337.1871643066406),\n",
       " (' ', 'K', 341.9036560058594),\n",
       " ('B', 'K', 346.8760070800781),\n",
       " ('o', 'K', 351.5966796875),\n",
       " ('t', 'K', 356.3040771484375),\n",
       " ('h', 'K', 361.0892333984375),\n",
       " (' ', 'K', 365.80572509765625),\n",
       " ('s', 'K', 370.5537109375),\n",
       " ('a', 'K', 375.6158447265625),\n",
       " ('i', 'K', 380.3579406738281),\n",
       " ('d', 'K', 385.1054992675781),\n",
       " (' ', 'K', 389.8219909667969),\n",
       " ('t', 'K', 394.5293884277344),\n",
       " ('h', 'K', 399.3145446777344),\n",
       " ('e', 'K', 404.2718811035156),\n",
       " ('y', 'K', 409.3191223144531),\n",
       " (' ', 'K', 414.0356140136719),\n",
       " ('\"', 'K', 419.016357421875),\n",
       " ('l', 'K', 423.9294128417969),\n",
       " ('o', 'K', 428.65008544921875),\n",
       " ('v', 'K', 433.4726257324219),\n",
       " ('e', 'K', 438.4299621582031),\n",
       " ('\"', 'K', 443.41070556640625),\n",
       " (' ', 'K', 448.127197265625),\n",
       " ('e', 'K', 453.08453369140625),\n",
       " ('a', 'K', 458.14666748046875),\n",
       " ('c', 'K', 462.96173095703125),\n",
       " ('h', 'K', 467.74688720703125),\n",
       " (' ', 'K', 472.46337890625),\n",
       " ('o', 'K', 477.1840515136719),\n",
       " ('t', 'K', 481.8914489746094),\n",
       " ('h', 'K', 486.6766052246094),\n",
       " ('e', 'K', 491.6339416503906),\n",
       " ('r', 'K', 496.46014404296875),\n",
       " ('.', 'K', 501.3348388671875),\n",
       " ('T', 'K', 506.0411682128906),\n",
       " ('h', 'K', 510.8263244628906),\n",
       " ('e', 'K', 515.7836303710938),\n",
       " ('y', 'K', 520.8308715820312),\n",
       " (' ', 'K', 525.54736328125),\n",
       " ('d', 'K', 530.294921875),\n",
       " ('o', 'K', 535.015625),\n",
       " ('n', 'K', 539.947998046875),\n",
       " ('t', 'K', 544.6553955078125),\n",
       " (' ', 'K', 549.3718872070312),\n",
       " ('-', 'K', 554.2496948242188),\n",
       " (' ', 'K', 558.9661865234375),\n",
       " ('w', 'K', 563.7919311523438),\n",
       " ('o', 'K', 568.5126342773438),\n",
       " ('r', 'K', 573.3388061523438),\n",
       " ('d', 'K', 578.0863647460938),\n",
       " (' ', 'K', 582.8028564453125),\n",
       " ('i', 'K', 587.544921875),\n",
       " ('s', 'K', 592.2929077148438),\n",
       " (' ', 'K', 597.0093994140625),\n",
       " ('h', 'K', 601.7945556640625),\n",
       " ('a', 'K', 606.856689453125),\n",
       " ('t', 'K', 611.5640869140625),\n",
       " ('e', 'K', 616.5214233398438),\n",
       " ('!', 'K', 621.3153076171875),\n",
       " ('', 'K', 626.0846557617188),\n",
       " ('d', ' ', 4.826395034790039),\n",
       " ('e', ' ', 9.561176300048828),\n",
       " ('r', ' ', 14.311601638793945),\n",
       " ('s', ' ', 18.93412971496582),\n",
       " (' ', ' ', 23.391345977783203),\n",
       " ('i', ' ', 28.044187545776367),\n",
       " ('s', ' ', 32.6668701171875),\n",
       " (' ', ' ', 37.12403869628906),\n",
       " ('b', ' ', 42.076377868652344),\n",
       " ('e', ' ', 46.813411712646484),\n",
       " ('i', ' ', 51.46624755859375),\n",
       " ('n', ' ', 56.31513214111328),\n",
       " ('g', ' ', 61.15196228027344),\n",
       " (' ', ' ', 65.609130859375),\n",
       " ('t', ' ', 70.14366149902344),\n",
       " ('r', ' ', 74.89917755126953),\n",
       " ('e', ' ', 79.6362075805664),\n",
       " ('a', ' ', 84.59680938720703),\n",
       " ('t', ' ', 89.13134002685547),\n",
       " ('e', ' ', 93.86837005615234),\n",
       " ('d', ' ', 98.5139389038086),\n",
       " (' ', ' ', 102.97110748291016),\n",
       " ('v', ' ', 107.74679565429688),\n",
       " ('e', ' ', 112.48382568359375),\n",
       " ('r', ' ', 117.23934173583984),\n",
       " ('y', ' ', 122.25276184082031),\n",
       " (' ', ' ', 126.70993041992188),\n",
       " ('b', ' ', 131.6622772216797),\n",
       " ('a', ' ', 136.6228790283203),\n",
       " ('d', ' ', 141.26844787597656),\n",
       " ('l', ' ', 146.1305694580078),\n",
       " ('y', ' ', 151.1439971923828),\n",
       " (' ', ' ', 155.60116577148438),\n",
       " ('b', ' ', 160.5535125732422),\n",
       " ('y', ' ', 165.5669403076172),\n",
       " (' ', ' ', 170.02410888671875),\n",
       " ('t', ' ', 174.5586395263672),\n",
       " ('h', ' ', 179.15753173828125),\n",
       " ('e', ' ', 183.89456176757812),\n",
       " (' ', ' ', 188.3517303466797),\n",
       " ('D', ' ', 193.31199645996094),\n",
       " ('e', ' ', 198.0490264892578),\n",
       " ('m', ' ', 202.98388671875),\n",
       " ('o', ' ', 207.58084106445312),\n",
       " ('c', ' ', 212.30886840820312),\n",
       " ('r', ' ', 217.06439208984375),\n",
       " ('a', ' ', 222.02499389648438),\n",
       " ('t', ' ', 226.5595245361328),\n",
       " ('s', ' ', 231.1822052001953),\n",
       " (' ', ' ', 235.63937377929688),\n",
       " ('-', ' ', 240.52224731445312),\n",
       " (' ', ' ', 244.9794158935547),\n",
       " ('t', ' ', 249.51394653320312),\n",
       " ('h', ' ', 254.1128387451172),\n",
       " ('e', ' ', 258.8498840332031),\n",
       " (' ', ' ', 263.30706787109375),\n",
       " ('s', ' ', 267.92974853515625),\n",
       " ('y', ' ', 272.94317626953125),\n",
       " ('s', ' ', 277.56585693359375),\n",
       " ('t', ' ', 282.1003723144531),\n",
       " ('e', ' ', 286.83740234375),\n",
       " ('m', ' ', 291.77227783203125),\n",
       " (' ', ' ', 296.2294616699219),\n",
       " ('i', ' ', 300.8822937011719),\n",
       " ('s', ' ', 305.5049743652344),\n",
       " (' ', ' ', 309.962158203125),\n",
       " ('r', ' ', 314.7176818847656),\n",
       " ('i', ' ', 319.3705139160156),\n",
       " ('g', ' ', 324.20733642578125),\n",
       " ('g', ' ', 329.0441589355469),\n",
       " ('e', ' ', 333.78118896484375),\n",
       " ('d', ' ', 338.4267578125),\n",
       " (' ', ' ', 342.8839416503906),\n",
       " ('a', ' ', 347.84454345703125),\n",
       " ('g', ' ', 352.6813659667969),\n",
       " ('a', ' ', 357.6419677734375),\n",
       " ('i', ' ', 362.2947998046875),\n",
       " ('n', ' ', 367.1436767578125),\n",
       " ('s', ' ', 371.766357421875),\n",
       " ('t', ' ', 376.3008728027344),\n",
       " (' ', ' ', 380.758056640625),\n",
       " ('h', ' ', 385.3569641113281),\n",
       " ('i', ' ', 390.0097961425781),\n",
       " ('m', ' ', 394.9446716308594),\n",
       " ('.', ' ', 399.7832946777344),\n",
       " (' ', ' ', 404.240478515625),\n",
       " ('M', ' ', 409.2660217285156),\n",
       " ('a', ' ', 414.22662353515625),\n",
       " ('n', ' ', 419.07550048828125),\n",
       " ('y', ' ', 424.08892822265625),\n",
       " (' ', ' ', 428.5461120605469),\n",
       " ('o', ' ', 433.14306640625),\n",
       " ('f', ' ', 438.08673095703125),\n",
       " (' ', ' ', 442.5439147949219),\n",
       " ('h', ' ', 447.142822265625),\n",
       " ('i', ' ', 451.795654296875),\n",
       " ('s', ' ', 456.4183349609375),\n",
       " (' ', ' ', 460.8755187988281),\n",
       " ('d', ' ', 465.5210876464844),\n",
       " ('i', ' ', 470.1739196777344),\n",
       " ('s', ' ', 474.7966003417969),\n",
       " ('e', ' ', 479.53363037109375),\n",
       " ('n', ' ', 484.38250732421875),\n",
       " ('f', ' ', 489.326171875),\n",
       " ('r', ' ', 494.0816955566406),\n",
       " ('a', ' ', 499.04229736328125),\n",
       " ('n', ' ', 503.89117431640625),\n",
       " ('c', ' ', 508.61920166015625),\n",
       " ('h', ' ', 513.2180786132812),\n",
       " ('i', ' ', 517.8709106445312),\n",
       " ('s', ' ', 522.4935913085938),\n",
       " ('e', ' ', 527.2306518554688),\n",
       " ('d', ' ', 531.876220703125),\n",
       " (' ', ' ', 536.3333740234375),\n",
       " ('f', ' ', 541.2770385742188),\n",
       " ('a', ' ', 546.2376098632812),\n",
       " ('n', ' ', 551.0864868164062),\n",
       " ('s', ' ', 555.7091674804688),\n",
       " (' ', ' ', 560.1663208007812),\n",
       " ('a', ' ', 565.1268920898438),\n",
       " ('r', ' ', 569.8823852539062),\n",
       " ('e', ' ', 574.6194458007812),\n",
       " (' ', ' ', 579.0765991210938),\n",
       " ('f', ' ', 584.020263671875),\n",
       " ('o', ' ', 588.6171875),\n",
       " ('r', ' ', 593.3726806640625),\n",
       " (' ', ' ', 597.829833984375),\n",
       " ('m', ' ', 602.7647094726562),\n",
       " ('e', ' ', 607.5017700195312),\n",
       " ('!', ' ', 612.3091430664062),\n",
       " ('', ' ', 617.0877685546875),\n",
       " ('e', ' ', 4.484245777130127),\n",
       " ('s', ' ', 8.954179763793945),\n",
       " (' ', ' ', 13.327369689941406),\n",
       " ('w', ' ', 18.17363166809082),\n",
       " ('e', ' ', 22.622514724731445),\n",
       " ('a', ' ', 27.305831909179688),\n",
       " ('k', ' ', 32.29510498046875),\n",
       " ('n', ' ', 36.961639404296875),\n",
       " ('e', ' ', 41.41053771972656),\n",
       " ('s', ' ', 45.87179946899414),\n",
       " ('s', ' ', 50.33306121826172),\n",
       " (' ', ' ', 54.706180572509766),\n",
       " ('i', ' ', 59.215633392333984),\n",
       " ('s', ' ', 63.67689514160156),\n",
       " (' ', ' ', 68.05001831054688),\n",
       " ('i', ' ', 72.5594711303711),\n",
       " ('t', ' ', 76.9764633178711),\n",
       " ('s', ' ', 81.4377212524414),\n",
       " (' ', ' ', 85.81084442138672),\n",
       " ('l', ' ', 90.61643981933594),\n",
       " ('o', ' ', 95.11106872558594),\n",
       " ('w', ' ', 99.95726013183594),\n",
       " (' ', ' ', 104.33038330078125),\n",
       " ('r', ' ', 108.9183578491211),\n",
       " ('a', ' ', 113.6016845703125),\n",
       " ('t', ' ', 118.0186767578125),\n",
       " ('i', ' ', 122.52812957763672),\n",
       " ('n', ' ', 127.19466400146484),\n",
       " ('g', ' ', 131.9857177734375),\n",
       " ('s', ' ', 136.4469757080078),\n",
       " ('.', ' ', 141.24671936035156),\n",
       " (' ', ' ', 145.61984252929688),\n",
       " ('I', ' ', 150.5496826171875),\n",
       " (' ', ' ', 154.9228057861328),\n",
       " ('d', ' ', 159.43820190429688),\n",
       " ('o', ' ', 163.93283081054688),\n",
       " ('n', ' ', 168.599365234375),\n",
       " ('t', ' ', 173.016357421875),\n",
       " (' ', ' ', 177.3894805908203),\n",
       " ('w', ' ', 182.2356719970703),\n",
       " ('a', ' ', 186.91900634765625),\n",
       " ('t', ' ', 191.33599853515625),\n",
       " ('c', ' ', 195.95838928222656),\n",
       " ('h', ' ', 200.41416931152344),\n",
       " (' ', ' ', 204.78729248046875),\n",
       " ('a', ' ', 209.4706268310547),\n",
       " ('n', ' ', 214.1371612548828),\n",
       " ('y', ' ', 219.04248046875),\n",
       " ('m', ' ', 223.9226837158203),\n",
       " ('o', ' ', 228.4173126220703),\n",
       " ('r', ' ', 233.0052947998047),\n",
       " ('e', ' ', 237.45419311523438),\n",
       " (' ', ' ', 241.8273162841797),\n",
       " ('b', ' ', 246.76686096191406),\n",
       " ('u', ' ', 251.40432739257812),\n",
       " ('t', ' ', 255.82131958007812),\n",
       " (' ', ' ', 260.1944274902344),\n",
       " ('I', ' ', 265.124267578125),\n",
       " (' ', ' ', 269.49737548828125),\n",
       " ('h', ' ', 273.9531555175781),\n",
       " ('e', ' ', 278.4020690917969),\n",
       " ('a', ' ', 283.08538818359375),\n",
       " ('r', ' ', 287.6733703613281),\n",
       " ('d', ' ', 292.18878173828125),\n",
       " (' ', ' ', 296.5618896484375),\n",
       " ('h', ' ', 301.0176696777344),\n",
       " ('e', ' ', 305.4665832519531),\n",
       " (' ', ' ', 309.8396911621094),\n",
       " ('w', ' ', 314.6858825683594),\n",
       " ('e', ' ', 319.1347961425781),\n",
       " ('n', ' ', 323.80133056640625),\n",
       " ('t', ' ', 328.21832275390625),\n",
       " (' ', ' ', 332.5914306640625),\n",
       " ('w', ' ', 337.4376220703125),\n",
       " ('i', ' ', 341.94708251953125),\n",
       " ('l', ' ', 346.752685546875),\n",
       " ('d', ' ', 351.2680969238281),\n",
       " (' ', ' ', 355.6412048339844),\n",
       " ('a', ' ', 360.32452392578125),\n",
       " ('g', ' ', 365.1155700683594),\n",
       " ('a', ' ', 369.79888916015625),\n",
       " ('i', ' ', 374.308349609375),\n",
       " ('n', ' ', 378.9748840332031),\n",
       " ('s', ' ', 383.4361572265625),\n",
       " ('t', ' ', 387.8531494140625),\n",
       " (' ', ' ', 392.22625732421875),\n",
       " ('R', ' ', 397.2091064453125),\n",
       " ('u', ' ', 401.8465576171875),\n",
       " ('d', ' ', 406.3619689941406),\n",
       " ('y', ' ', 411.26727294921875),\n",
       " (' ', ' ', 415.640380859375),\n",
       " ('G', ' ', 420.5444641113281),\n",
       " ('i', ' ', 425.0539245605469),\n",
       " ('u', ' ', 429.6913757324219),\n",
       " ('l', ' ', 434.4969787597656),\n",
       " ('i', ' ', 439.0064392089844),\n",
       " ('a', ' ', 443.68975830078125),\n",
       " ('n', ' ', 448.3562927246094),\n",
       " ('i', ' ', 452.8657531738281),\n",
       " (' ', ' ', 457.2388610839844),\n",
       " ('a', ' ', 461.92218017578125),\n",
       " ('n', ' ', 466.5887145996094),\n",
       " ('d', ' ', 471.1041259765625),\n",
       " (' ', ' ', 475.47723388671875),\n",
       " ('#', ' ', 480.2837829589844),\n",
       " ('2', ' ', 485.1118469238281),\n",
       " ('A', ' ', 490.0044250488281),\n",
       " (' ', ' ', 494.3775329589844),\n",
       " ('-', ' ', 499.26226806640625),\n",
       " (' ', ' ', 503.6353759765625),\n",
       " ('s', ' ', 508.0966491699219),\n",
       " ('a', ' ', 512.7799682617188),\n",
       " ('d', ' ', 517.2953491210938),\n",
       " (' ', ' ', 521.66845703125),\n",
       " ('&', ' ', 526.5087890625),\n",
       " ('a', ' ', 531.192138671875),\n",
       " ('m', ' ', 536.0723266601562),\n",
       " ('p', ' ', 540.8342895507812),\n",
       " (';', ' ', 545.7619018554688),\n",
       " (' ', ' ', 550.135009765625),\n",
       " ('i', ' ', 554.6444702148438),\n",
       " ('r', ' ', 559.232421875),\n",
       " ('r', ' ', 563.8203735351562),\n",
       " ('e', ' ', 568.269287109375),\n",
       " ('l', ' ', 573.0748901367188),\n",
       " ('e', ' ', 577.5238037109375),\n",
       " ('v', ' ', 582.2481079101562),\n",
       " ('a', ' ', 586.9314575195312),\n",
       " ('n', ' ', 591.5979614257812),\n",
       " ('t', ' ', 596.0149536132812),\n",
       " ('!', ' ', 600.8377685546875),\n",
       " ('', ' ', 605.6241455078125),\n",
       " (' ', ' ', 4.351102828979492),\n",
       " ('@', ' ', 9.28280258178711),\n",
       " ('D', ' ', 14.267501831054688),\n",
       " ('o', ' ', 18.68232536315918),\n",
       " ('n', ' ', 23.13619613647461),\n",
       " ('a', ' ', 27.5489559173584),\n",
       " ('l', ' ', 32.231910705566406),\n",
       " ('d', ' ', 36.642486572265625),\n",
       " ('J', ' ', 41.70716857910156),\n",
       " ('T', ' ', 46.42683410644531),\n",
       " ('r', ' ', 50.871192932128906),\n",
       " ('u', ' ', 55.46064758300781),\n",
       " ('m', ' ', 60.25157928466797),\n",
       " ('p', ' ', 65.00069427490234),\n",
       " ('J', ' ', 70.06537628173828),\n",
       " ('r', ' ', 74.50973510742188),\n",
       " ('!', ' ', 79.33233642578125),\n",
       " (' ', ' ', 83.67707824707031),\n",
       " ('#', ' ', 88.48576354980469),\n",
       " ('T', ' ', 93.20542907714844),\n",
       " ('r', ' ', 97.64978790283203),\n",
       " ('u', ' ', 102.23924255371094),\n",
       " ('m', ' ', 107.0301742553711),\n",
       " ('p', ' ', 111.77928924560547),\n",
       " ('2', ' ', 116.64517211914062),\n",
       " ('0', ' ', 121.5215835571289),\n",
       " ('1', ' ', 126.40181732177734),\n",
       " ('6', ' ', 131.46768188476562),\n",
       " (' ', ' ', 135.8124237060547),\n",
       " ('#', ' ', 140.62110900878906),\n",
       " ('M', ' ', 145.67706298828125),\n",
       " ('a', ' ', 150.08982849121094),\n",
       " ('k', ' ', 155.08750915527344),\n",
       " ('e', ' ', 159.44407653808594),\n",
       " ('A', ' ', 164.29339599609375),\n",
       " ('m', ' ', 169.08432006835938),\n",
       " ('e', ' ', 173.44088745117188),\n",
       " ('r', ' ', 177.88525390625),\n",
       " ('i', ' ', 182.28257751464844),\n",
       " ('c', ' ', 186.80886840820312),\n",
       " ('a', ' ', 191.2216339111328),\n",
       " ('G', ' ', 196.13327026367188),\n",
       " ('r', ' ', 200.57763671875),\n",
       " ('e', ' ', 204.9342041015625),\n",
       " ('a', ' ', 209.3469696044922),\n",
       " ('t', ' ', 213.70559692382812),\n",
       " ('A', ' ', 218.55491638183594),\n",
       " ('g', ' ', 223.2700958251953),\n",
       " ('a', ' ', 227.682861328125),\n",
       " ('i', ' ', 232.08018493652344),\n",
       " ('n', ' ', 236.53408813476562),\n",
       " ('\\n', ' ', 241.37200927734375),\n",
       " ('h', ' ', 245.7483367919922),\n",
       " ('t', ' ', 250.10696411132812),\n",
       " ('t', ' ', 254.46559143066406),\n",
       " ('p', ' ', 259.2147216796875),\n",
       " ('s', ' ', 263.5875549316406),\n",
       " (':', ' ', 268.34588623046875),\n",
       " ('/', ' ', 272.9378662109375),\n",
       " ('/', ' ', 277.52984619140625),\n",
       " ('t', ' ', 281.8884582519531),\n",
       " ('.', ' ', 286.64569091796875),\n",
       " ('c', ' ', 291.1719665527344),\n",
       " ('o', ' ', 295.58697509765625),\n",
       " ('/', ' ', 300.178955078125),\n",
       " ('F', ' ', 305.0809631347656),\n",
       " ('J', ' ', 310.1456604003906),\n",
       " ('X', ' ', 315.1019592285156),\n",
       " ('j', ' ', 320.0263671875),\n",
       " ('k', ' ', 325.0240478515625),\n",
       " ('Z', ' ', 329.6898193359375),\n",
       " ('A', ' ', 334.53912353515625),\n",
       " ('A', ' ', 339.388427734375),\n",
       " ('Q', ' ', 344.3671569824219),\n",
       " ('f', ' ', 349.1751708984375),\n",
       " (' ', ' ', 353.5199279785156),\n",
       " ('h', ' ', 357.8962707519531),\n",
       " ('t', ' ', 362.2548828125),\n",
       " ('t', ' ', 366.6134948730469),\n",
       " ('p', ' ', 371.36260986328125),\n",
       " ('s', ' ', 375.7354431152344),\n",
       " (':', ' ', 380.4937744140625),\n",
       " ('/', ' ', 385.08575439453125),\n",
       " ('/', ' ', 389.677734375),\n",
       " ('t', ' ', 394.0363464355469),\n",
       " ('.', ' ', 398.7935791015625),\n",
       " ('c', ' ', 403.3198547363281),\n",
       " ('o', ' ', 407.73486328125),\n",
       " ('/', ' ', 412.32684326171875),\n",
       " ('0', ' ', 417.2032470703125),\n",
       " ('N', ' ', 422.0234375),\n",
       " ('Q', ' ', 427.0021667480469),\n",
       " ('L', ' ', 432.1390686035156),\n",
       " ('z', ' ', 437.1463623046875),\n",
       " ('b', ' ', 442.0616149902344),\n",
       " ('w', ' ', 446.8326721191406),\n",
       " ('u', ' ', 451.422119140625),\n",
       " ('F', ' ', 456.3241271972656),\n",
       " ('o', ' ', 460.7391357421875),\n",
       " ('', ' ', 465.5173645019531),\n",
       " ('w', ' ', 4.618138790130615),\n",
       " ('h', ' ', 8.950868606567383),\n",
       " ('a', ' ', 13.281142234802246),\n",
       " ('t', ' ', 17.60424041748047),\n",
       " (' ', ' ', 21.923521041870117),\n",
       " ('B', ' ', 26.987743377685547),\n",
       " ('i', ' ', 31.325002670288086),\n",
       " ('l', ' ', 35.886722564697266),\n",
       " ('l', ' ', 40.44844055175781),\n",
       " (' ', ' ', 44.76771545410156),\n",
       " ('C', ' ', 49.533878326416016),\n",
       " ('l', ' ', 54.09559631347656),\n",
       " ('i', ' ', 58.432857513427734),\n",
       " ('n', ' ', 62.78633499145508),\n",
       " ('t', ' ', 67.1094970703125),\n",
       " ('o', ' ', 71.46448516845703),\n",
       " ('n', ' ', 75.81796264648438),\n",
       " (' ', ' ', 80.13723754882812),\n",
       " ('s', ' ', 84.46475982666016),\n",
       " ('a', ' ', 88.79491424560547),\n",
       " ('y', ' ', 93.43512725830078),\n",
       " ('s', ' ', 97.76264953613281),\n",
       " (' ', ' ', 102.08192443847656),\n",
       " ('a', ' ', 106.41207885742188),\n",
       " ('n', ' ', 110.76555633544922),\n",
       " ('d', ' ', 115.11334991455078),\n",
       " (' ', ' ', 119.43262481689453),\n",
       " ('n', ' ', 123.78610229492188),\n",
       " ('o', ' ', 128.14108276367188),\n",
       " (' ', ' ', 132.46035766601562),\n",
       " ('m', ' ', 137.12049865722656),\n",
       " ('a', ' ', 141.45065307617188),\n",
       " ('t', ' ', 145.77381896972656),\n",
       " ('t', ' ', 150.09698486328125),\n",
       " ('e', ' ', 154.41795349121094),\n",
       " ('r', ' ', 158.77516174316406),\n",
       " (' ', ' ', 163.0944366455078),\n",
       " ('h', ' ', 167.4247283935547),\n",
       " ('o', ' ', 171.7797088623047),\n",
       " ('w', ' ', 176.4664306640625),\n",
       " (' ', ' ', 180.78570556640625),\n",
       " ('w', ' ', 185.47242736816406),\n",
       " ('e', ' ', 189.79339599609375),\n",
       " ('l', ' ', 194.35511779785156),\n",
       " ('l', ' ', 198.91683959960938),\n",
       " (' ', ' ', 203.23611450195312),\n",
       " ('h', ' ', 207.56640625),\n",
       " ('e', ' ', 211.8873748779297),\n",
       " (' ', ' ', 216.20664978027344),\n",
       " ('s', ' ', 220.53416442871094),\n",
       " ('a', ' ', 224.86431884765625),\n",
       " ('y', ' ', 229.50453186035156),\n",
       " ('s', ' ', 233.83204650878906),\n",
       " (' ', ' ', 238.1513214111328),\n",
       " ('i', ' ', 242.48858642578125),\n",
       " ('t', ' ', 246.81175231933594),\n",
       " (',', ' ', 251.73455810546875),\n",
       " (' ', ' ', 256.0538330078125),\n",
       " ('t', ' ', 260.3769836425781),\n",
       " ('h', ' ', 264.707275390625),\n",
       " ('e', ' ', 269.02825927734375),\n",
       " (' ', ' ', 273.3475341796875),\n",
       " ('p', ' ', 278.0238037109375),\n",
       " ('h', ' ', 282.3540954589844),\n",
       " ('o', ' ', 286.7090759277344),\n",
       " ('n', ' ', 291.06256103515625),\n",
       " ('y', ' ', 295.7027587890625),\n",
       " (' ', ' ', 300.02203369140625),\n",
       " ('m', ' ', 304.68218994140625),\n",
       " ('e', ' ', 309.003173828125),\n",
       " ('d', ' ', 313.3509521484375),\n",
       " ('i', ' ', 317.6882019042969),\n",
       " ('a', ' ', 322.01837158203125),\n",
       " (' ', ' ', 326.337646484375),\n",
       " ('w', ' ', 331.02435302734375),\n",
       " ('i', ' ', 335.3616027832031),\n",
       " ('l', ' ', 339.9233093261719),\n",
       " ('l', ' ', 344.4850158691406),\n",
       " (' ', ' ', 348.8042907714844),\n",
       " ('e', ' ', 353.1252746582031),\n",
       " ('x', ' ', 358.070068359375),\n",
       " ('c', ' ', 362.5075988769531),\n",
       " ('l', ' ', 367.0693054199219),\n",
       " ('a', ' ', 371.39947509765625),\n",
       " ('i', ' ', 375.7367248535156),\n",
       " ('m', ' ', 380.3968811035156),\n",
       " (' ', ' ', 384.7161560058594),\n",
       " ('i', ' ', 389.05340576171875),\n",
       " ('t', ' ', 393.3765563964844),\n",
       " (' ', ' ', 397.6958312988281),\n",
       " ('t', ' ', 402.01898193359375),\n",
       " ('o', ' ', 406.37396240234375),\n",
       " (' ', ' ', 410.6932373046875),\n",
       " ('b', ' ', 415.5692443847656),\n",
       " ('e', ' ', 419.8902282714844),\n",
       " (' ', ' ', 424.2095031738281),\n",
       " ('i', ' ', 428.5467529296875),\n",
       " ('n', ' ', 432.9002380371094),\n",
       " ('c', ' ', 437.3377685546875),\n",
       " ('r', ' ', 441.6949768066406),\n",
       " ('e', ' ', 446.0159606933594),\n",
       " ('d', ' ', 450.3637390136719),\n",
       " ('i', ' ', 454.70098876953125),\n",
       " ('b', ' ', 459.5769958496094),\n",
       " ('l', ' ', 464.1387023925781),\n",
       " ('e', ' ', 468.4596862792969),\n",
       " ('.', ' ', 473.1470642089844),\n",
       " (' ', ' ', 477.4663391113281),\n",
       " ('H', ' ', 482.4533386230469),\n",
       " ('i', ' ', 486.79058837890625),\n",
       " ('g', ' ', 491.41845703125),\n",
       " ('h', ' ', 495.7487487792969),\n",
       " ('l', ' ', 500.3104553222656),\n",
       " ('y', ' ', 504.9506530761719),\n",
       " (' ', ' ', 509.2699279785156),\n",
       " ('o', ' ', 513.6249389648438),\n",
       " ('v', ' ', 518.2466430664062),\n",
       " ('e', ' ', 522.567626953125),\n",
       " ('r', ' ', 526.9248046875),\n",
       " ('r', ' ', 531.281982421875),\n",
       " ('a', ' ', 535.6121215820312),\n",
       " ('t', ' ', 539.935302734375),\n",
       " ('e', ' ', 544.2562866210938),\n",
       " ('d', ' ', 548.6040649414062),\n",
       " ('!', ' ', 553.4144287109375),\n",
       " ('', ' ', 558.1774291992188),\n",
       " (' ', ' ', 4.302553653717041),\n",
       " ('s', ' ', 8.596080780029297),\n",
       " ('o', ' ', 12.90310287475586),\n",
       " ('.', ' ', 17.525083541870117),\n",
       " (' ', ' ', 21.814916610717773),\n",
       " ('O', ' ', 26.601160049438477),\n",
       " ('u', ' ', 31.064714431762695),\n",
       " ('r', ' ', 35.36823654174805),\n",
       " (' ', ' ', 39.65806198120117),\n",
       " ('c', ' ', 44.02133560180664),\n",
       " ('o', ' ', 48.32838821411133),\n",
       " ('u', ' ', 52.79194259643555),\n",
       " ('n', ' ', 57.09170150756836),\n",
       " ('t', ' ', 61.38260269165039),\n",
       " ('r', ' ', 65.68612670898438),\n",
       " ('y', ' ', 70.1793212890625),\n",
       " (' ', ' ', 74.46914672851562),\n",
       " ('t', ' ', 78.76004791259766),\n",
       " ('o', ' ', 83.06710052490234),\n",
       " ('t', ' ', 87.35800170898438),\n",
       " ('a', ' ', 91.64950561523438),\n",
       " ('l', ' ', 96.05018615722656),\n",
       " ('l', ' ', 100.45086669921875),\n",
       " ('y', ' ', 104.94406127929688),\n",
       " (' ', ' ', 109.23388671875),\n",
       " ('l', ' ', 113.63456726074219),\n",
       " ('o', ' ', 117.94161987304688),\n",
       " ('s', ' ', 122.23384857177734),\n",
       " ('t', ' ', 126.52474975585938),\n",
       " (' ', ' ', 130.8145751953125),\n",
       " ('c', ' ', 135.17784118652344),\n",
       " ('o', ' ', 139.48489379882812),\n",
       " ('n', ' ', 143.78465270996094),\n",
       " ('t', ' ', 148.0755615234375),\n",
       " ('r', ' ', 152.37908935546875),\n",
       " ('o', ' ', 156.68614196777344),\n",
       " ('l', ' ', 161.08682250976562),\n",
       " (' ', ' ', 165.37664794921875),\n",
       " ('o', ' ', 169.68370056152344),\n",
       " ('f', ' ', 174.39144897460938),\n",
       " (' ', ' ', 178.6812744140625),\n",
       " ('i', ' ', 182.97686767578125),\n",
       " ('l', ' ', 187.37754821777344),\n",
       " ('l', ' ', 191.77822875976562),\n",
       " ('e', ' ', 196.0683135986328),\n",
       " ('g', ' ', 200.6112060546875),\n",
       " ('a', ' ', 204.9027099609375),\n",
       " ('l', ' ', 209.3033905029297),\n",
       " (' ', ' ', 213.5932159423828),\n",
       " ('i', ' ', 217.88880920410156),\n",
       " ('m', ' ', 222.4034881591797),\n",
       " ('m', ' ', 226.9181671142578),\n",
       " ('i', ' ', 231.21376037597656),\n",
       " ('g', ' ', 235.75665283203125),\n",
       " ('r', ' ', 240.0601806640625),\n",
       " ('a', ' ', 244.3516845703125),\n",
       " ('t', ' ', 248.642578125),\n",
       " ('i', ' ', 252.93817138671875),\n",
       " ('o', ' ', 257.2452392578125),\n",
       " ('n', ' ', 261.5450134277344),\n",
       " (',', ' ', 266.4736328125),\n",
       " (' ', ' ', 270.7634582519531),\n",
       " ('e', ' ', 275.05352783203125),\n",
       " ('v', ' ', 279.6324157714844),\n",
       " ('e', ' ', 283.9224853515625),\n",
       " ('n', ' ', 288.2222595214844),\n",
       " (' ', ' ', 292.5120849609375),\n",
       " ('w', ' ', 297.0740966796875),\n",
       " ('i', ' ', 301.36968994140625),\n",
       " ('t', ' ', 305.66058349609375),\n",
       " ('h', ' ', 309.9541931152344),\n",
       " (' ', ' ', 314.2440185546875),\n",
       " ('c', ' ', 318.6072998046875),\n",
       " ('r', ' ', 322.91082763671875),\n",
       " ('i', ' ', 327.2064208984375),\n",
       " ('m', ' ', 331.7210998535156),\n",
       " ('i', ' ', 336.0166931152344),\n",
       " ('n', ' ', 340.31646728515625),\n",
       " ('a', ' ', 344.60797119140625),\n",
       " ('l', ' ', 349.0086669921875),\n",
       " ('s', ' ', 353.3009033203125),\n",
       " ('.', ' ', 357.9227600097656),\n",
       " ('\\n', ' ', 362.79022216796875),\n",
       " ('h', ' ', 367.0838317871094),\n",
       " ('t', ' ', 371.3747253417969),\n",
       " ('t', ' ', 375.6656188964844),\n",
       " ('p', ' ', 380.2677307128906),\n",
       " ('s', ' ', 384.5599670410156),\n",
       " (':', ' ', 389.1989440917969),\n",
       " ('/', ' ', 393.6149597167969),\n",
       " ('/', ' ', 398.0309753417969),\n",
       " ('t', ' ', 402.3218688964844),\n",
       " ('.', ' ', 406.9437255859375),\n",
       " ('c', ' ', 411.3070068359375),\n",
       " ('o', ' ', 415.61407470703125),\n",
       " ('/', ' ', 420.03009033203125),\n",
       " ('I', ' ', 424.9493408203125),\n",
       " ('Z', ' ', 429.6218566894531),\n",
       " ('g', ' ', 434.1647644042969),\n",
       " ('Z', ' ', 438.8372802734375),\n",
       " ('q', ' ', 443.67608642578125),\n",
       " ('r', ' ', 447.9796142578125),\n",
       " ('6', ' ', 453.112548828125),\n",
       " ('B', ' ', 458.1910400390625),\n",
       " ('g', ' ', 462.73394775390625),\n",
       " ('B', ' ', 467.81243896484375),\n",
       " ('', ' ', 472.5540771484375),\n",
       " ('a', ' ', 4.276363372802734),\n",
       " ('n', ' ', 8.54238510131836),\n",
       " (' ', ' ', 12.803778648376465),\n",
       " ('g', ' ', 17.243789672851562),\n",
       " ('a', ' ', 21.505409240722656),\n",
       " ('v', ' ', 26.0452938079834),\n",
       " ('e', ' ', 30.306684494018555),\n",
       " (' ', ' ', 34.56803512573242),\n",
       " ('a', ' ', 38.82965087890625),\n",
       " (' ', ' ', 43.09100341796875),\n",
       " ('f', ' ', 47.7584342956543),\n",
       " ('a', ' ', 52.020050048828125),\n",
       " ('n', ' ', 56.28425598144531),\n",
       " ('t', ' ', 60.54590606689453),\n",
       " ('a', ' ', 64.8075180053711),\n",
       " ('s', ' ', 69.06957244873047),\n",
       " ('t', ' ', 73.33122253417969),\n",
       " ('i', ' ', 77.59439849853516),\n",
       " ('c', ' ', 81.8984375),\n",
       " (' ', ' ', 86.1597900390625),\n",
       " ('i', ' ', 90.42296600341797),\n",
       " ('n', ' ', 94.68717193603516),\n",
       " ('t', ' ', 98.94882202148438),\n",
       " ('e', ' ', 103.21021270751953),\n",
       " ('r', ' ', 107.47640228271484),\n",
       " ('v', ' ', 112.01628112792969),\n",
       " ('i', ' ', 116.27945709228516),\n",
       " ('e', ' ', 120.54084777832031),\n",
       " ('w', ' ', 124.99765014648438),\n",
       " (' ', ' ', 129.25900268554688),\n",
       " ('t', ' ', 133.52066040039062),\n",
       " ('h', ' ', 137.78330993652344),\n",
       " ('i', ' ', 142.04649353027344),\n",
       " ('s', ' ', 146.3085479736328),\n",
       " (' ', ' ', 150.5699005126953),\n",
       " ('m', ' ', 154.9617462158203),\n",
       " ('o', ' ', 159.2310333251953),\n",
       " ('r', ' ', 163.49722290039062),\n",
       " ('n', ' ', 167.7614288330078),\n",
       " ('i', ' ', 172.0246124267578),\n",
       " ('n', ' ', 176.288818359375),\n",
       " ('g', ' ', 180.7289276123047),\n",
       " (' ', ' ', 184.9902801513672),\n",
       " ('o', ' ', 189.2595672607422),\n",
       " ('n', ' ', 193.52377319335938),\n",
       " (' ', ' ', 197.78512573242188),\n",
       " ('@', ' ', 202.78311157226562),\n",
       " ('C', ' ', 207.66513061523438),\n",
       " ('N', ' ', 212.58868408203125),\n",
       " ('N', ' ', 217.51223754882812),\n",
       " (' ', ' ', 221.77359008789062),\n",
       " ('-', ' ', 226.7154083251953),\n",
       " (' ', ' ', 230.9767608642578),\n",
       " ('w', ' ', 235.43356323242188),\n",
       " ('a', ' ', 239.69517517089844),\n",
       " ('y', ' ', 244.0733642578125),\n",
       " (' ', ' ', 248.334716796875),\n",
       " ('t', ' ', 252.59637451171875),\n",
       " ('o', ' ', 256.86566162109375),\n",
       " (' ', ' ', 261.12701416015625),\n",
       " ('g', ' ', 265.567138671875),\n",
       " ('o', ' ', 269.83642578125),\n",
       " (' ', ' ', 274.0977783203125),\n",
       " ('P', ' ', 279.1994934082031),\n",
       " ('a', ' ', 283.46112060546875),\n",
       " ('t', ' ', 287.7227783203125),\n",
       " (',', ' ', 292.6509704589844),\n",
       " (' ', ' ', 296.9123229980469),\n",
       " ('w', ' ', 301.369140625),\n",
       " ('a', ' ', 305.6307678222656),\n",
       " ('y', ' ', 310.0089416503906),\n",
       " (' ', ' ', 314.2702941894531),\n",
       " ('a', ' ', 318.53192138671875),\n",
       " ('h', ' ', 322.7945556640625),\n",
       " ('e', ' ', 327.0559387207031),\n",
       " ('a', ' ', 331.31756591796875),\n",
       " ('d', ' ', 335.5841064453125),\n",
       " (' ', ' ', 339.845458984375),\n",
       " ('o', ' ', 344.11474609375),\n",
       " ('f', ' ', 348.78216552734375),\n",
       " (' ', ' ', 353.04351806640625),\n",
       " ('y', ' ', 357.42169189453125),\n",
       " ('o', ' ', 361.69097900390625),\n",
       " ('u', ' ', 366.0977478027344),\n",
       " ('r', ' ', 370.3639221191406),\n",
       " (' ', ' ', 374.6252746582031),\n",
       " ('t', ' ', 378.8869323730469),\n",
       " ('i', ' ', 383.1501159667969),\n",
       " ('m', ' ', 387.5419616699219),\n",
       " ('e', ' ', 391.8033447265625),\n",
       " ('!', ' ', 396.6009826660156),\n",
       " ('', ' ', 401.3180236816406),\n",
       " ('e', ' ', 4.250094890594482),\n",
       " ('t', ' ', 8.487045288085938),\n",
       " ('N', ' ', 13.432180404663086),\n",
       " (':', ' ', 17.97712516784668),\n",
       " (' ', ' ', 22.21265983581543),\n",
       " ('G', ' ', 27.14020538330078),\n",
       " ('o', ' ', 31.37932014465332),\n",
       " (' ', ' ', 35.61485290527344),\n",
       " ('D', ' ', 40.64000701904297),\n",
       " ('o', ' ', 44.87912368774414),\n",
       " ('n', ' ', 49.115474700927734),\n",
       " ('a', ' ', 53.35104751586914),\n",
       " ('l', ' ', 57.59944152832031),\n",
       " ('d', ' ', 61.837215423583984),\n",
       " ('.', ' ', 66.30142211914062),\n",
       " ('.', ' ', 70.765625),\n",
       " ('.', ' ', 75.22982788085938),\n",
       " ('N', ' ', 80.17444610595703),\n",
       " ('o', ' ', 84.41355895996094),\n",
       " ('w', ' ', 88.7746810913086),\n",
       " ('h', ' ', 93.01065826416016),\n",
       " ('e', ' ', 97.2461929321289),\n",
       " ('r', ' ', 101.48342895507812),\n",
       " ('e', ' ', 105.71896362304688),\n",
       " (' ', ' ', 109.95449829101562),\n",
       " ('i', ' ', 114.19060516357422),\n",
       " ('n', ' ', 118.42695617675781),\n",
       " (' ', ' ', 122.66249084472656),\n",
       " ('t', ' ', 126.89810943603516),\n",
       " ('h', ' ', 131.13409423828125),\n",
       " ('e', ' ', 135.36962890625),\n",
       " (' ', ' ', 139.60516357421875),\n",
       " ('C', ' ', 144.5415802001953),\n",
       " ('o', ' ', 148.78070068359375),\n",
       " ('n', ' ', 153.01705932617188),\n",
       " ('s', ' ', 157.25279235839844),\n",
       " ('t', ' ', 161.4884033203125),\n",
       " ('i', ' ', 165.72450256347656),\n",
       " ('t', ' ', 169.96011352539062),\n",
       " ('u', ' ', 174.3167266845703),\n",
       " ('t', ' ', 178.55233764648438),\n",
       " ('i', ' ', 182.78843688964844),\n",
       " ('o', ' ', 187.02755737304688),\n",
       " ('n', ' ', 191.263916015625),\n",
       " (' ', ' ', 195.49945068359375),\n",
       " ('d', ' ', 199.7372283935547),\n",
       " ('o', ' ', 203.97634887695312),\n",
       " ('e', ' ', 208.21188354492188),\n",
       " ('s', ' ', 212.44761657714844),\n",
       " (' ', ' ', 216.6831512451172),\n",
       " ('i', ' ', 220.91925048828125),\n",
       " ('t', ' ', 225.1548614501953),\n",
       " (' ', ' ', 229.39039611816406),\n",
       " ('s', ' ', 233.62612915039062),\n",
       " ('a', ' ', 237.86170959472656),\n",
       " ('y', ' ', 242.1580352783203),\n",
       " (' ', ' ', 246.39356994628906),\n",
       " ('t', ' ', 250.62918090820312),\n",
       " ('h', ' ', 254.8651580810547),\n",
       " ('a', ' ', 259.1007385253906),\n",
       " ('t', ' ', 263.33636474609375),\n",
       " (' ', ' ', 267.5718994140625),\n",
       " ('o', ' ', 271.8110046386719),\n",
       " ('u', ' ', 276.1676330566406),\n",
       " ('r', ' ', 280.4048767089844),\n",
       " (' ', ' ', 284.6404113769531),\n",
       " ('P', ' ', 289.7630920410156),\n",
       " ('r', ' ', 294.0003356933594),\n",
       " ('e', ' ', 298.2358703613281),\n",
       " ('s', ' ', 302.47161865234375),\n",
       " ('i', ' ', 306.7077331542969),\n",
       " ('d', ' ', 310.94549560546875),\n",
       " ('e', ' ', 315.1810302734375),\n",
       " ('n', ' ', 319.4173889160156),\n",
       " ('t', ' ', 323.65301513671875),\n",
       " (' ', ' ', 327.8885498046875),\n",
       " ('m', ' ', 332.1949157714844),\n",
       " ('u', ' ', 336.5515441894531),\n",
       " ('s', ' ', 340.78729248046875),\n",
       " ('t', ' ', 345.0229187011719),\n",
       " (' ', ' ', 349.2584533691406),\n",
       " ('b', ' ', 353.9822692871094),\n",
       " ('e', ' ', 358.2178039550781),\n",
       " (' ', ' ', 362.4533386230469),\n",
       " ('a', ' ', 366.68890380859375),\n",
       " (' ', ' ', 370.9244384765625),\n",
       " ('l', ' ', 375.1728210449219),\n",
       " ('a', ' ', 379.40838623046875),\n",
       " ('w', ' ', 383.7695007324219),\n",
       " ('y', ' ', 388.0658264160156),\n",
       " ('e', ' ', 392.3013610839844),\n",
       " ('r', ' ', 396.5386047363281),\n",
       " ('/', ' ', 400.833251953125),\n",
       " ('p', ' ', 405.3130798339844),\n",
       " ('o', ' ', 409.55218505859375),\n",
       " ('l', ' ', 413.8005676269531),\n",
       " ('i', ' ', 418.03668212890625),\n",
       " ('t', ' ', 422.2723083496094),\n",
       " ('i', ' ', 426.5084228515625),\n",
       " ('c', ' ', 430.7684631347656),\n",
       " ('i', ' ', 435.00457763671875),\n",
       " ('a', ' ', 439.2401428222656),\n",
       " ('n', ' ', 443.47650146484375),\n",
       " ('.', ' ', 447.9407043457031),\n",
       " (' ', ' ', 452.1762390136719),\n",
       " ('O', ' ', 457.034912109375),\n",
       " ('u', ' ', 461.39154052734375),\n",
       " ('r', ' ', 465.6287841796875),\n",
       " (' ', ' ', 469.86431884765625),\n",
       " ('f', ' ', 474.47491455078125),\n",
       " ('o', ' ', 478.7140197753906),\n",
       " ('u', ' ', 483.0706481933594),\n",
       " ('n', ' ', 487.3070068359375),\n",
       " ('d', ' ', 491.5447692871094),\n",
       " ('e', ' ', 495.7803039550781),\n",
       " ...]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.diffHisto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"@RepMartinDaniel: We support you #HaileyPuckett. You will go far in life. Smart and courageous!\n",
      "\"@RepMarti\n",
      "Variable containing:\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      " 32\n",
      "[torch.LongTensor of size 101]\n",
      "\n",
      "                                                                                                     \n"
     ]
    }
   ],
   "source": [
    "t = tweet()\n",
    "tCut = t[:10]\n",
    "te = Variable(toohot(torch.LongTensor(encode(tCut))), volatile = True)\n",
    "z = Variable(torch.zeros(zLen).type(torch.FloatTensor), volatile = True)\n",
    "r, z = m.predict(te, z)\n",
    "print(t)\n",
    "print(tCut)\n",
    "print(tofint(r))\n",
    "print(decode(tofint(r)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bon ça ne marche tjs pas, on vas passer au lstm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, rnncell=nn.RNN):\n",
    "        \n",
    "        super(LSTM, self).__init__()        \n",
    "        \n",
    "        self.input_size  = input_size    # Vocabulaire\n",
    "        self.hidden_size = hidden_size   # Mémoire\n",
    "        self.output_size = output_size   # Vocabulaire\n",
    "        \n",
    "        self.forgetGate = nn.Sigmoid()\n",
    "        self.inputGate  = nn.Sigmoid()\n",
    "        self.writeGate  = nn.Tanh()\n",
    "        self.readGate   = nn.Tanh()\n",
    "        self.outputGate = nn.Sigmoid()\n",
    "        \n",
    "        self.c = torch.randn((1, 1, hidden_size))\n",
    "    \n",
    "    def forward(self, x, h):\n",
    "        \n",
    "        # Initial concatenation\n",
    "        inp = torch.cat((x, h), 0)\n",
    "        \n",
    "        # Forget Gate\n",
    "        forget = self.forgetGate(inp)\n",
    "        self.c *= forget\n",
    "        \n",
    "        # Write\n",
    "        it = self.inputGate(inp)\n",
    "        ct = self.writeGate(inp)\n",
    "        self.c += ct * it\n",
    "        \n",
    "        # Read\n",
    "        rc = self.readGate(self.c)\n",
    "        ot = self.outputGate(inp)\n",
    "        \n",
    "        return rc*ot\n",
    "    \n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        \n",
    "        \n",
    "    def generate(self, start=\"A\", length=160):\n",
    "        \n",
    "        hidden = self.init_hidden()\n",
    "        input = encode(start)\n",
    "        final = start\n",
    "        \n",
    "        # Préparation hidden\n",
    "        for c in input[:-1]:\n",
    "            _, hidden = self.forward(c, hidden)\n",
    "        input = input[-1]\n",
    "        \n",
    "        for p in range(length - len(start)):\n",
    "            output, hidden = self.forward(input, hidden)\n",
    "            out = output.max(0)[1]\n",
    "            if out == FINAL_CHAR:\n",
    "                break\n",
    "            final.append(decode(out))\n",
    "            input = out\n",
    "            \n",
    "        return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqLSTM(object):\n",
    "    def __init__(self, recurIn, recurOut, stop, maxLen = 100, debug = False):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.recurIn = recurIn\n",
    "        self.recurOut = recurOut\n",
    "        self.stop = stop\n",
    "        self.maxLen = maxLen\n",
    "        self.debug = debug\n",
    "        if self.debug :\n",
    "            self.lossHisto = []\n",
    "            self.diffHisto = []\n",
    "    \n",
    "    def predict(self, boot, z):\n",
    "        for i in boot:\n",
    "            z = self.recurIn(i,z)\n",
    "        r = []\n",
    "        cpt = 1\n",
    "        x, z = self.recurOut(boot[-1],z)\n",
    "        r.append(x)\n",
    "        while tofint(x.data)[0] != tofint(self.stop)[0] and cpt <= self.maxLen:\n",
    "            cpt +=1\n",
    "            x, z = self.recurOut(x,z)\n",
    "            r.append(x)\n",
    "        \n",
    "        r = torch.stack(r)\n",
    "        return r, z\n",
    "    \n",
    "    def train(self, inputs, z, outputs):\n",
    "        '''\n",
    "            :param inputs: Input sequence\n",
    "        '''\n",
    "        loss = nn.CrossEntropyLoss()\n",
    "        sgdIn  = optim.SGD(self.recurIn.parameters(), lr=1e-3)\n",
    "        sgdOut  = optim.SGD(self.recurOut.parameters(), lr=1e-3)\n",
    "        \n",
    "        for i in inputs[:-1]:\n",
    "            z = self.recurIn(i, z)\n",
    "            \n",
    "        r = inputs[-1]\n",
    "        l = 0\n",
    "        for i in outputs:\n",
    "            r, z = self.recurOut(r, z)\n",
    "            l += loss.forward(r.unsqueeze(0), i)\n",
    "            if self.debug : self.lossHisto.append(l.data.mean())\n",
    "            if self.debug : self.diffHisto.append((decode(i), decode(tofint(r)), l.data.mean()))\n",
    "                \n",
    "        l.backward()   \n",
    "        sgdIn.step()\n",
    "        sgdOut.step()\n",
    "        \n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "zLen = 1000\n",
    "recurIn = Encoder(zLen, VOCAB_SIZE+1)\n",
    "recurOut = Recurent(zLen, VOCAB_SIZE+1)\n",
    "m = Seq2Seq(recurIn, recurOut, toohot(torch.LongTensor([FINAL_CHAR])), debug = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Iteration 100\n",
      "Iteration 200\n",
      "Iteration 300\n",
      "Iteration 400\n",
      "Iteration 500\n",
      "Iteration 600\n",
      "Iteration 700\n",
      "Iteration 800\n",
      "Iteration 900\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb772fb4b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TRAIN_ITER = 1000\n",
    "lossHisto = []\n",
    "diffHisto = []\n",
    "for i in range(TRAIN_ITER):\n",
    "    \n",
    "    if i%(TRAIN_ITER/10) == 0:\n",
    "        print(\"Iteration\", i)\n",
    "    \n",
    "    t = tweet()\n",
    "    #print(t)\n",
    "    \n",
    "    x = Variable(toohot(torch.LongTensor(encode(t[:10]))))\n",
    "    y = Variable(torch.LongTensor(encode(t[10:])))\n",
    "    z = Variable(torch.zeros(zLen).type(torch.FloatTensor))\n",
    "    m.train(x, z, y)\n",
    "\n",
    "plt.plot(m.lossHisto)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('nb batch traited')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
