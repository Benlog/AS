{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "nbpresent": {
     "id": "88a05bb0-aed1-474c-8cc3-72d7688ca8d2"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import random as rd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbpresent": {
     "id": "726dd813-5008-46e2-a350-638d4d5aeb7f"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./as-tp6')\n",
    "from charDataset import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Dataset Trump Tweets\n",
    "\n",
    "On utilise l'ensemble des tweets postés par Donald Trump."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7372</th>\n",
       "      <td>Irrelevant clown @KarlRove sweats and shakes n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>In Tampa, Florida- thank you to all of our out...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5034</th>\n",
       "      <td>I think it would be a good ideaand fairto incl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4098</th>\n",
       "      <td>Getting ready to go to the great State of Mich...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>The media is so dishonest. If I make a stateme...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Tweet_Text\n",
       "7372  Irrelevant clown @KarlRove sweats and shakes n...\n",
       "1773  In Tampa, Florida- thank you to all of our out...\n",
       "5034  I think it would be a good ideaand fairto incl...\n",
       "4098  Getting ready to go to the great State of Mich...\n",
       "1503  The media is so dishonest. If I make a stateme..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"trump.csv\", dtype=str, delimiter=\",\", usecols=[2])\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise les fonctions ord et chr pour facilement convertir les caractères en valeurs numériques, et on crée les ensembles d'apprentissage et de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "#TWEET_SIZE = 280\n",
    "VOCAB_SIZE = 128\n",
    "#FINAL_CHAR = 160 # espace insécable\n",
    "FINAL_CHAR = VOCAB_SIZE\n",
    " \n",
    "BLANK_OHOT = torch.FloatTensor(BATCH_SIZE, VOCAB_SIZE+1).zero_()\n",
    " \n",
    "def encode(row):\n",
    "   \n",
    "    # Conversion en int, et suppression des cractères spéciaux (emojis, bugs, etc)\n",
    "    l = [ord(c) for c in row[0] if ord(c) < VOCAB_SIZE] #[:TWEET_SIZE-1] et limitation en taille (aberrations csv)\n",
    "   \n",
    "    # Normalisation longueur tweets\n",
    "    '''\n",
    "    for i in range(len(l), TWEET_SIZE-1):\n",
    "        l.append(FINAL_CHAR)\n",
    "    l.append(FINAL_CHAR)\n",
    "    '''    \n",
    "   \n",
    "    # Ajout caractère de fin (espace insécable)\n",
    "    l.append(FINAL_CHAR)\n",
    "   \n",
    "    return l\n",
    "\n",
    "\n",
    "def decode(row):\n",
    "    return ''.join([chr(int(c)) for c in row if int(c) != FINAL_CHAR])\n",
    " \n",
    "\n",
    "def toohot(value):\n",
    "    blank = torch.FloatTensor(len(value), VOCAB_SIZE+1).zero_()\n",
    "    return blank.scatter_(1, value.view(-1, 1), 1)\n",
    " \n",
    "\n",
    "def tofint(onehot):\n",
    "    return onehot.max(-1)[1][0]\n",
    "\n",
    "\n",
    "#data_e = data.apply(encode, axis=1)\n",
    "#train = Variable(torch.Tensor(data_e[0:16000].as_matrix()))  # .view(-1, BATCH_SIZE, TWEET_SIZE)\n",
    "#test  = Variable(torch.Tensor(data_e[16000:20800].as_matrix()))  # .view(-1, BATCH_SIZE, TWEET_SIZE)\n",
    " \n",
    "dataset = [c for r in data.apply(encode, axis=1) for c in r] # Conversion et applatissement\n",
    "#dataset = dataset[:-(len(dataset)%BATCH_SIZE)]               # Coupe taille divisible en batchs entiers\n",
    "train   = torch.LongTensor(dataset[:700000])\n",
    "test    = torch.LongTensor(dataset[700000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(raw=train, length=50, index=None):\n",
    "    if index is None:\n",
    "        index = rd.randint(0, len(train))\n",
    "    return raw[index:index+length]#, raw[index+1:index+length+1]\n",
    "\n",
    "def tweet(raw=data):\n",
    "    return data.sample().iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ial interests-only the U.S.A.!When I look at all of the money the special interests and lobbyists are giving to candidates, beware - the candidates are mere puppets $$$$!I hope Bill Clinton starts t'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(sample(train, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I watched lightweight Senator  Marco Rubio, who is all talk and no action, defend his WEAK position on illegal immigration. Pathetic!'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample().iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "nbpresent": {
     "id": "40ed8f3e-73f1-4614-965b-1a62d18c1b84"
    }
   },
   "outputs": [],
   "source": [
    "class Recurent(nn.Module):\n",
    "    def __init__(self, tailleZ, tailleVoc, actF = nn.Sigmoid()):\n",
    "        '''X et Y vecteur onehot de taille tailleVoc\n",
    "        Z vecteur de stockage de taille tailleZ'''\n",
    "        super(Recurent, self).__init__()\n",
    "        self.XToY = nn.Linear(tailleVoc, tailleVoc)\n",
    "        self.XToZ = nn.Linear(tailleVoc, tailleZ)\n",
    "        self.ZToY = nn.Linear(tailleZ, tailleVoc)\n",
    "        self.ZToZ = nn.Linear(tailleZ, tailleZ)\n",
    "        self.actF = actF\n",
    "\n",
    "    def forward(self, x, z):\n",
    "        '''return Y, Z'''\n",
    "        #print(\"x\", x, \"z\", z)\n",
    "        return self.actF(self.XToY(x) + self.ZToY(z)), self.actF(self.XToZ(x) + self.ZToZ(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "nbpresent": {
     "id": "9f3217b3-cd0a-461b-9a7d-154809350665"
    }
   },
   "outputs": [],
   "source": [
    "class RecurentGated(nn.Module):\n",
    "    def __init__(self, tailleZ, tailleVoc, actF = nn.Sigmoid()):\n",
    "        '''X et Y vecteur onehot de taille tailleVoc\n",
    "        Z vecteur de stockage de taille tailleZ'''\n",
    "        super(Recurent, self).__init__()\n",
    "        self.XToY = nn.Linear(tailleVoc, tailleVoc)\n",
    "        self.XToZ = nn.Linear(tailleVoc, tailleZ)\n",
    "        self.ZToY = nn.Linear(tailleZ, tailleVoc)\n",
    "        self.ZToZ = nn.Linear(tailleZ, tailleZ)\n",
    "        self.gateZ = nn.Linear(tailleVoc, tailleZ)\n",
    "        self.gateY = nn.Linear(tailleVoc, tailleVoc)\n",
    "        self.actF = actF\n",
    "\n",
    "    def forward(self, x, z):\n",
    "        '''return Z, Y'''\n",
    "        soft = torch.nn.Softmax(-1)\n",
    "        return soft(self.XtoZ(x)) * self.actF(self.gateZ(x)) + self.actF(self.ZtoZ(z)) * (1-self.actF(self.gateZ(x))),\\\n",
    "    self.actF(self.XtoY(x)) * self.actF(self.gateY(x)) + self.actF(self.ZtoY(z)) + (1 - self.actF(self.gateY(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "nbpresent": {
     "id": "b626bc25-a3b4-439b-9061-93af485b008b"
    }
   },
   "outputs": [],
   "source": [
    "class RNNMono():\n",
    "    def __init__(self, recur, stop):\n",
    "        super(RNNMono, self).__init__()\n",
    "        self.recur = recur\n",
    "        self.stop = stop\n",
    "    \n",
    "    def predict(self, boot, z):\n",
    "        for i in boot:\n",
    "            z, x = self.recur(i,z)\n",
    "        r = []\n",
    "        r.append(x)\n",
    "        while (x.max(-1)[1].data != self.stop.max(-1)[1]).all() :\n",
    "            z, x = self.recur(x,z)\n",
    "            #print(voc.inverse[x.max(-1)[1].data[-1]])\n",
    "            r.append(x)\n",
    "        return r, z\n",
    "    \n",
    "    def train(self, inputs, z):\n",
    "        '''\n",
    "            :param inputs: Input sequence\n",
    "        '''\n",
    "        loss = nn.MSELoss()\n",
    "        sgd  = optim.SGD(self.recur.parameters(), lr=1e-3)\n",
    "        \n",
    "        i = Variable(BLANK_OHOT.zero_())\n",
    "        r, z = self.recur(i, z)\n",
    "        loss.forward(i, r).backward()\n",
    "        sgd.step()\n",
    "        \n",
    "        for i in inputs:\n",
    "            r, z = self.recur(i, z)\n",
    "            loss.forward(i, r).backward()\n",
    "            sgd.step()\n",
    "        \n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "matrices expected, got 1D, 2D tensors at /opt/conda/conda-bld/pytorch_1501969512886/work/pytorch-0.1.12/torch/lib/TH/generic/THTensorMath.c:1232",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-b8cab5e5e4a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzLen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-76-e3f936ecb049>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, inputs, z)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBLANK_OHOT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecur\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0msgd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-10e0fb776204>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, z)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;34m'''return Y, Z'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m#print(\"x\", x, \"z\", z)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXToY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZToY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXToZ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZToZ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/myenv/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv/lib/python3.5/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv/lib/python3.5/site-packages/torch/nn/_functions/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;31m# cuBLAS doesn't support 0 strides in sger, so we can't use expand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: matrices expected, got 1D, 2D tensors at /opt/conda/conda-bld/pytorch_1501969512886/work/pytorch-0.1.12/torch/lib/TH/generic/THTensorMath.c:1232"
     ]
    }
   ],
   "source": [
    "zLen = 1000\n",
    "recur = Recurent(zLen, VOCAB_SIZE+1)\n",
    "m = RNNMono(recur, toohot(torch.LongTensor([FINAL_CHAR])))\n",
    "TRAIN_ITER = 500\n",
    "\n",
    "lossHisto = []\n",
    "scoreHisto = []\n",
    "\n",
    "for i in range(TRAIN_ITER):\n",
    "    \n",
    "    if i%(TRAIN_ITER/10) == 0:\n",
    "        print(\"Iteration\", i)\n",
    "    \n",
    "    x = Variable(toohot(torch.LongTensor(encode(tweet()))))\n",
    "    z = autograd.Variable(torch.zeros(zLen).type(torch.FloatTensor))\n",
    "    \n",
    "    f,_ = m.train(x, z)\n",
    "    print(f, y)\n",
    "    loss = ml.forward(f, y).backward()\n",
    "    opt.step()\n",
    "    \n",
    "    lossHisto.append(loss.data.mean())\n",
    "    ypred = torch.max(f, 1)[1]\n",
    "    scoreHisto.append(torch.eq(ypred.data, yN).float().mean())\n",
    "    \n",
    "plt.plot(lossHisto)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('nb batch traited')\n",
    "plt.show()\n",
    "plt.plot(scoreHisto)\n",
    "plt.ylabel('score')\n",
    "plt.xlabel('nb batch traited')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "class RNNMono(nn.Module):\n",
    "    def __init__(self, recur, stop):\n",
    "        super(RNNMono, self).__init__()\n",
    "        self.recur = recur\n",
    "        self.stop = stop\n",
    "    \n",
    "    def forward(self, boot, z):\n",
    "        for i in boot:\n",
    "            z, x = self.recur(i,z)\n",
    "        x = x.max(0)[1]\n",
    "        x = x.unsqueeze(-1).scatter(-1, x, 1.)\n",
    "        r = x.unsqueeze(0)\n",
    "        while (x != self.stop).all() :\n",
    "            z, x = self.recur(x,z)\n",
    "            '''xm = x.max(0)[1]\n",
    "            x_onehot = torch.FloatTensor(*xm.size(), x.size()[0]).zero_()\n",
    "            x_onehot.scatter_(1, torch.unsqueeze(xm.data, 1), 1.)\n",
    "            x = x_onehot'''\n",
    "            x = x.max(0)[1]\n",
    "            x = x.unsqueeze(-1).scatter_(-1, x, 1.)\n",
    "            r.cat(x.unsqueeze_(-1),0)\n",
    "        return r, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "13c683a1-4314-4f4b-ba89-9595c02e7205"
    }
   },
   "outputs": [],
   "source": [
    "def sequencer(x, end):\n",
    "    r = []\n",
    "    for i in x :\n",
    "        r.append(i)\n",
    "        if i == end :\n",
    "            yield r\n",
    "            r = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "nbpresent": {
     "id": "26de8649-3e8a-4a05-baad-d2ef655bafd3"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dave aneckstein4 simmons research4 an ezperian company they have not been charged or formally arrested5 iran isnt making an atomic bomb4 not at all4 chave.\n",
      " said monday5 the japanesemade tin robots have blocky heads and moveable arms and legs5 if they could no longer be the nominees4 then they would be pundits of the first order men with credibility on oval office matters by dint of once sitting in the chair themselves5 free challenge kits have a cd and brochure from dr5 ian4 menu and fitness advice and a pedometer to count steps5 the world motor sport council received statements from fernando alonso4 lewis hamilton and pedro de la rosa stating categorically no ferrari information had been used by mclaren4 and that no confidential data had been passed to the team5 the prime minister said the first citi.\n"
     ]
    }
   ],
   "source": [
    "for i in sequencer(ten[:1000], 35):\n",
    "    print(code2char(i, voc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "0f3b34d4-3d05-4851-b49d-e71603744639"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "zLen = 1000\n",
    "vocLen = 36\n",
    "recur = Recurent(zLen, vocLen)\n",
    "\n",
    "endN = torch.LongTensor([vocLen-1])\n",
    "end_onehot = torch.FloatTensor(*endN.size(), vocLen).zero_()\n",
    "end_onehot.scatter_(1, torch.unsqueeze(endN, 1), 1.)\n",
    "\n",
    "m = RNNMono(recur, end_onehot)\n",
    "ml = nn.MSELoss()\n",
    "ite = 500\n",
    "opt = optim.SGD(m.parameters(), lr=1e-3)\n",
    "\n",
    "lossHisto = []\n",
    "scoreHisto = []\n",
    "\n",
    "for i,seq in enumerate(sequencer(ten, 35)):\n",
    "    if i > ite :\n",
    "        break\n",
    "    if i%(ite/10) == 0:\n",
    "        print(\"Iteration\", i)\n",
    "    \n",
    "    xN = torch.LongTensor(seq[:30])\n",
    "    x_onehot = torch.FloatTensor(*xN.size(), vocLen).zero_()\n",
    "    x_onehot.scatter_(1, torch.unsqueeze(xN, 1), 1.)\n",
    "    x = autograd.Variable(x_onehot.type(torch.FloatTensor))\n",
    "    \n",
    "    yN = torch.LongTensor(seq[30:])\n",
    "    y_onehot = torch.FloatTensor(*yN.size(), vocLen).zero_()\n",
    "    y_onehot.scatter_(1, torch.unsqueeze(yN, 1), 1.)\n",
    "    y = autograd.Variable(y_onehot.type(torch.FloatTensor))\n",
    "    \n",
    "    z = autograd.Variable(torch.zeros(zLen).type(torch.FloatTensor))\n",
    "    \n",
    "    f,_ = m.forward(x, z)\n",
    "    print(f, y)\n",
    "    loss = ml.forward(f, y)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    \n",
    "    lossHisto.append(loss.data.mean())\n",
    "    ypred = torch.max(f, 1)[1]\n",
    "    scoreHisto.append(torch.eq(ypred.data, yN).float().mean())\n",
    "    \n",
    "plt.plot(lossHisto)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('nb batch traited')\n",
    "plt.show()\n",
    "plt.plot(scoreHisto)\n",
    "plt.ylabel('score')\n",
    "plt.xlabel('nb batch traited')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "44b57bc0-5a12-4da5-a879-305849b19a34"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
