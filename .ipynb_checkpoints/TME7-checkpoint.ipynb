{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./as-tp6')\n",
    "from charDataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Recurent(nn.Module):\n",
    "    def __init__(self, tailleZ, tailleVoc, actF = nn.Sigmoid()):\n",
    "        '''X et Y vecteur onehot de taille tailleVoc\n",
    "        Z vecteur de stockage de taille tailleZ'''\n",
    "        super(Recurent, self).__init__()\n",
    "        self.XToY = nn.Linear(tailleVoc, tailleVoc)\n",
    "        self.XToZ = nn.Linear(tailleVoc, tailleZ)\n",
    "        self.ZToY = nn.Linear(tailleZ, tailleVoc)\n",
    "        self.ZToZ = nn.Linear(tailleZ, tailleZ)\n",
    "        self.actF = actF\n",
    "\n",
    "    def forward(self, x, z):\n",
    "        '''return Z, Y'''\n",
    "        return self.actF(self.XToZ(x) + self.ZToZ(z)), self.actF(self.XToY(x) + self.ZToY(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RecurentGated(nn.Module):\n",
    "    def __init__(self, tailleZ, tailleVoc, actF = nn.Sigmoid()):\n",
    "        '''X et Y vecteur onehot de taille tailleVoc\n",
    "        Z vecteur de stockage de taille tailleZ'''\n",
    "        super(Recurent, self).__init__()\n",
    "        self.XToY = nn.Linear(tailleVoc, tailleVoc)\n",
    "        self.XToZ = nn.Linear(tailleVoc, tailleZ)\n",
    "        self.ZToY = nn.Linear(tailleZ, tailleVoc)\n",
    "        self.ZToZ = nn.Linear(tailleZ, tailleZ)\n",
    "        self.gateZ = nn.Linear(tailleVoc, tailleZ)\n",
    "        self.gateY = nn.Linear(tailleVoc, tailleVoc)\n",
    "        self.actF = actF\n",
    "\n",
    "    def forward(self, x, z):\n",
    "        '''return Z, Y'''\n",
    "        return self.actF(self.XtoZ(x)) * self.actF(self.gateZ(x)) + self.actF(self.ZtoZ(z)) * (1-self.actF(self.gateZ(x))),\\\n",
    "    self.actF(self.XtoY(x)) * self.actF(self.gateY(x)) + self.actF(self.ZtoY(z)) + (1 - self.actF(self.gateY(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fData = \"./as-tp6/train_data.tx\"\n",
    "fVoc = \"./as-tp6/vocab.tx\"\n",
    "ten = torch.load(fData)\n",
    "rawVoc = torch.load(fVoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class bidict(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(bidict, self).__init__(*args, **kwargs)\n",
    "        self.inverse = {}\n",
    "        for key, value in self.items():\n",
    "            self.inverse.setdefault(value,[]).append(key) \n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        if key in self:\n",
    "            self.inverse[self[key]].remove(key) \n",
    "        super(bidict, self).__setitem__(key, value)\n",
    "        self.inverse.setdefault(value,[]).append(key)        \n",
    "\n",
    "    def __delitem__(self, key):\n",
    "        self.inverse.setdefault(self[key],[]).remove(key)\n",
    "        if self[key] in self.inverse and not self.inverse[self[key]]: \n",
    "            del self.inverse[self[key]]\n",
    "        super(bidict, self).__delitem__(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "voc = bidict(rawVoc)\n",
    "voc[' '] = 1\n",
    "voc['0'] = 0\n",
    "voc['.'] = 35\n",
    "voc['z'] = 33\n",
    "voc['y'] = 34\n",
    "voc['y'] = 34\n",
    "voc['w'] = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 1,\n",
       " '.': 35,\n",
       " '0': 0,\n",
       " '1': 2,\n",
       " '2': 3,\n",
       " '3': 4,\n",
       " '4': 5,\n",
       " '5': 6,\n",
       " '7': 7,\n",
       " '8': 8,\n",
       " '_': 9,\n",
       " 'a': 10,\n",
       " 'b': 11,\n",
       " 'c': 12,\n",
       " 'd': 13,\n",
       " 'e': 14,\n",
       " 'f': 15,\n",
       " 'g': 16,\n",
       " 'h': 17,\n",
       " 'i': 18,\n",
       " 'j': 19,\n",
       " 'k': 20,\n",
       " 'l': 21,\n",
       " 'm': 22,\n",
       " 'n': 23,\n",
       " 'o': 24,\n",
       " 'p': 25,\n",
       " 'q': 26,\n",
       " 'r': 27,\n",
       " 's': 28,\n",
       " 't': 29,\n",
       " 'u': 30,\n",
       " 'v': 31,\n",
       " 'w': 32,\n",
       " 'x': 32,\n",
       " 'y': 34,\n",
       " 'z': 33}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNNMono(nn.Module):\n",
    "    def __init__(self, recur, stop):\n",
    "        super(RNNMono, self).__init__()\n",
    "        self.recur = recur\n",
    "        self.stop = stop\n",
    "    \n",
    "    def forward(self, boot, z):\n",
    "        for i in boot:\n",
    "            z, x = self.recur(i,z)\n",
    "        xm = x.max(0)[1]\n",
    "        x_onehot = torch.FloatTensor(*xm.size(), x.size()[0]).zero_()\n",
    "        x_onehot.scatter_(1, torch.unsqueeze(xm, 1), 1.)\n",
    "        x = autograd.Variable(x_onehot)\n",
    "        r = []\n",
    "        r.append(x)\n",
    "        print(x, self.stop)\n",
    "        while x.max(0)[1] != self.stop.max(0)[1] :\n",
    "            z, x = self.recur(x,z)\n",
    "            xm = x.max(0)[1]\n",
    "            x_onehot = torch.FloatTensor(*xm.size(), x.size()[0]).zero_()\n",
    "            x_onehot.scatter_(1, torch.unsqueeze(xm, 1), 1.)\n",
    "            x = autograd.Variable(x_onehot)\n",
    "            r.append(x)\n",
    "        return r, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sequencer(x, end):\n",
    "    r = []\n",
    "    for i in x :\n",
    "        r.append(i)\n",
    "        if i == end :\n",
    "            yield r\n",
    "            r = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dave aneckstein4 simmons research4 an ezperian company they have not been charged or formally arrested5 iran isnt making an atomic bomb4 not at all4 chave.\n",
      " said monday5 the japanesemade tin robots have blocky heads and moveable arms and legs5 if they could no longer be the nominees4 then they would be pundits of the first order men with credibility on oval office matters by dint of once sitting in the chair themselves5 free challenge kits have a cd and brochure from dr5 ian4 menu and fitness advice and a pedometer to count steps5 the world motor sport council received statements from fernando alonso4 lewis hamilton and pedro de la rosa stating categorically no ferrari information had been used by mclaren4 and that no confidential data had been passed to the team5 the prime minister said the first citi.\n"
     ]
    }
   ],
   "source": [
    "for i in sequencer(ten[:1000], 35):\n",
    "    print(code2char(i, voc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "scatter_ received an invalid combination of arguments - got (int, Variable, float), but expected one of:\n * (int dim, torch.LongTensor index, float value)\n      didn't match because some of the arguments have invalid types: (\u001b[32;1mint\u001b[0m, \u001b[31;1mVariable\u001b[0m, \u001b[32;1mfloat\u001b[0m)\n * (int dim, torch.LongTensor index, torch.FloatTensor src)\n      didn't match because some of the arguments have invalid types: (\u001b[32;1mint\u001b[0m, \u001b[31;1mVariable\u001b[0m, \u001b[31;1mfloat\u001b[0m)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-f257618a27d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzLen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-d74fdd96be1f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, boot, z)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mxm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mx_onehot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mx_onehot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_onehot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: scatter_ received an invalid combination of arguments - got (int, Variable, float), but expected one of:\n * (int dim, torch.LongTensor index, float value)\n      didn't match because some of the arguments have invalid types: (\u001b[32;1mint\u001b[0m, \u001b[31;1mVariable\u001b[0m, \u001b[32;1mfloat\u001b[0m)\n * (int dim, torch.LongTensor index, torch.FloatTensor src)\n      didn't match because some of the arguments have invalid types: (\u001b[32;1mint\u001b[0m, \u001b[31;1mVariable\u001b[0m, \u001b[31;1mfloat\u001b[0m)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "zLen = 1000\n",
    "vocLen = 36\n",
    "recur = Recurent(zLen, vocLen)\n",
    "\n",
    "endN = torch.LongTensor([vocLen-1])\n",
    "end_onehot = torch.FloatTensor(*endN.size(), vocLen).zero_()\n",
    "end_onehot.scatter_(1, torch.unsqueeze(endN, 1), 1.)\n",
    "\n",
    "m = RNNMono(recur, autograd.Variable(end_onehot))\n",
    "ml = nn.MSELoss()\n",
    "ite = 500\n",
    "opt = optim.SGD(m.parameters(), lr=1e-3)\n",
    "\n",
    "lossHisto = []\n",
    "scoreHisto = []\n",
    "\n",
    "for i,seq in enumerate(sequencer(ten, 35)):\n",
    "    if i > ite :\n",
    "        break\n",
    "    if i%(ite/10) == 0:\n",
    "        print(\"Iteration\", i)\n",
    "    \n",
    "    xN = torch.LongTensor(seq[:10])\n",
    "    x_onehot = torch.FloatTensor(*xN.size(), vocLen).zero_()\n",
    "    x_onehot.scatter_(1, torch.unsqueeze(xN, 1), 1.)\n",
    "    x = autograd.Variable(x_onehot)\n",
    "    \n",
    "    yN = torch.LongTensor(seq[10:])\n",
    "    y_onehot = torch.FloatTensor(*yN.size(), vocLen).zero_()\n",
    "    y_onehot.scatter_(1, torch.unsqueeze(yN, 1), 1.)\n",
    "    y = autograd.Variable(y_onehot)\n",
    "    \n",
    "    z = autograd.Variable(torch.zeros(zLen))\n",
    "    \n",
    "    f = m.forward(x, z)\n",
    "    loss = ml.forward(f, y)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    \n",
    "    lossHisto.append(loss.data.mean())\n",
    "    ypred = torch.max(f, 1)[1]\n",
    "    scoreHisto.append(torch.eq(ypred.data, yN).float().mean())\n",
    "    \n",
    "plt.plot(lossHisto)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('nb batch traited')\n",
    "plt.show()\n",
    "plt.plot(scoreHisto)\n",
    "plt.ylabel('score')\n",
    "plt.xlabel('nb batch traited')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
