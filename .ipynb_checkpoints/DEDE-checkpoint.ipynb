{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LinearModule(object):\n",
    "    def __init__(self, in_dim=1, out_dim=1, epsilon=0.01, follows=None, followed=None):\n",
    "        self.X = in_dim                                 # Dimension d'entrée\n",
    "        self.Y = out_dim                                # Dimenstion de sortie\n",
    "        self.E = epsilon                                # Pas de gradient\n",
    "        self.T = np.random.random_sample((self.X,))     # Theta aléatoire\n",
    "        self.G = np.zeros((self.X,))                    # Gradient à zéro\n",
    "        self.F = follows                                # Module suivant\n",
    "        self.B = followed                               # Module précédent\n",
    "\n",
    "    def forward(self, x):                               # f_theta(x)\n",
    "        return np.sum([x[i] * self.T[i] for i in range(self.X)])\n",
    "\n",
    "    def backward(self, x, delta):\n",
    "        self.G += delta*x\n",
    "        self.update()                                   # Stochastique : update theta systématique\n",
    "    \n",
    "    def update(self):\n",
    "        self.T -= self.G*self.E\n",
    "\n",
    "        \n",
    "class SigmoidModule(LinearModule):\n",
    "    def forward(self, x):\n",
    "        return (1 - np.exp(-2 * x)) / (1 + np.exp(-2 * x))\n",
    "\n",
    "    def backward(self, x, theta):\n",
    "        return theta * (4 * np.exp(-2 * x)) / ((1 + np.exp(-2 * x)) * (1 + np.exp(-2 * x)))\n",
    "\n",
    "\n",
    "class SquareLoss(object):\n",
    "    def __init__(self, dim):\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, y_predict, y_real):               # Delta(y, ^y)\n",
    "        return np.mean((y_predict - y_real) * (y_predict - y_real))\n",
    "\n",
    "    def backward(self, y_predict, y_real):              # V_y Delta(y, ^y)\n",
    "        return 2*(y_predict-y_real)\n",
    "\n",
    "    \n",
    "# TODO delete\n",
    "def read_libsvm(fname):\n",
    "    with open(fname) as f:\n",
    "        x,y  =list(),list()\n",
    "        for l in f:\n",
    "            line = l.strip().split(\" \")\n",
    "            y.append(int(line[0]))\n",
    "            x.append([float(s.split(\":\")[1]) for s in line[1:]])\n",
    "    return np.array(x),np.array(y)\n",
    "\n",
    "\n",
    "def load_mnist(filename):\n",
    "    with open(filename,\"r\") as f:\n",
    "        f.readline()\n",
    "        data =[ [float(x) for x in l.split()] for l in f if len(l.split())>2]\n",
    "    tmp = np.array(data)\n",
    "    return tmp[:,1:],tmp[:,0].astype(int)\n",
    "\n",
    "\n",
    "def show_usps(data):\n",
    "    plt.imshow(data.reshape((16,16)),interpolation=\"nearest\",cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyse données cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_x, data_y = read_libsvm(\"breast-cancer_scale\")\n",
    "size = data_x.shape[0]\n",
    "\n",
    "data_y = data_y - 3           # Normalisation des étiquettes\n",
    "\n",
    "in_dim = data_x.shape[1]\n",
    "out_dim = 1\n",
    "iters = 5000\n",
    "ggap = 1e-3\n",
    "module = LinearModule(in_dim, out_dim, ggap)\n",
    "loss = SquareLoss(out_dim)\n",
    "\n",
    "# Train\n",
    "data_x_a = data_x[:int(0.8*size)]\n",
    "data_y_a = data_y[:int(0.8*size)]\n",
    "\n",
    "# Tests\n",
    "data_x_t = data_x[int(0.8*size):]\n",
    "data_y_t = data_y[int(0.8*size):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAAkCAYAAACZmsEQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABUVJREFUeJzt3FuIVVUcx/HvTx3NW5iXREZNI4NEolRESEICyyxSgsgH\nySDopYeih1CEwkcLJKKnKKGr+lCWWEFaQkHkZfKSppOXpBzGRpOwopzMfw97TR6GGeeMOufo2r8P\nbM46a+8zZ/3W6N/tPvssRQRmZnbt61fvAZiZ2ZXhgm5mlgkXdDOzTLigm5llwgXdzCwTLuhmZpm4\nrIIuab6kZkmHJS27UoMyM7Pe67GgS1ovqV3S35L2S3pa0khJW4FPgInAcWCJpKl9PWAzM+taNWfo\na4HHgcPAbOAp4CVgROpbmY77FVh45YdoZmbV6LGgR8SHwNep/TtwALgXGAfsAN4ExgO3Ao19NlIz\nM7uoAb05WNIk4E5gONAA/AWcAEan51295m3gYYABA/sNGTS4y8PMzLI1pP/1TJw88ZJf39TUdCoi\nxvR0XG8Kej/gfeAZYA1wHpgQESEp0v6WLl73FXAbwLn289POtZ/d14v3zM1o4FS9B1FHZc5f5uxQ\n8vx/cnL0ydMnLyf/TdUcpGoW55J0C7ALeCEiVktqpvjHYADwCPAexWWXGRGx/yI/Z2dEzKxmYDly\n/vLmL3N2cP5a5e/xDF2SgFXA2YhYnbo3ArOAo8DHwFBg+8WKuZmZ9a1q7nL5jOIa+Kh0++JPwM60\n71FSMQcW9c0QzcysGj2eoUfEvG52rb+E93vtEl6TE+cvrzJnB+evSf6qrqGbmdnVz2u5mJlloiYF\nPdc1XyStkdQmaV9F30hJmyUdSo83VOxbnuagWdJ9Ff0zJH2X9r2SPoi+6kmaIGmrpO87loVI/dnP\ngaTrJG2XtCdlX5n6s89eSVJ/SbskbUrPS5Nf0rE07t2Sdqa++uaPiD7dgP7AEeBmYCCwB5ja1+9b\niw24G5gO7KvoexFYltrLgFWpPTVlHwRMTnPSP+3bTrGsgoBPgfvrna3K/OOA6ak9HPgh5cx+DtI4\nh6V2A7AtjT/77J3m4VmK25Y3peelyQ8cA0Z36qtr/lqcoc8CDkfE0YhoB9aRyZovEfElcLpT90KK\n5RBIj4sq+tdFxNmI+JFiHZxZksYB10fEN1H8dt/iGrljKCJaI+Lb1O5YFqKREsxBFP5ITxvSFpQg\newdJ44EHgNcrukuTvxt1zV+Lgt4I/Fzx/Dh5r/kyNiJaU/sEMDa1u5uHxtTu3H9NqVgWYhslmYN0\nuWE30AZsjojSZE9eBp6j+NZ4hzLlD2CLpCZJT6a+uubv1Vou1jsR/y+LkDVJw0jLQkTEmcpLgDnP\nQUT8C9whaQSwQdK0TvuzzS7pQaAtIpokze3qmJzzJ3MiokXSjcBmSQcrd9Yjfy3O0FuACRXPx9P1\nmi+5+CX9N4r02Jb6u5uHltTu3H9NkNRAUczfjYgPUnep5iAifgO2AvMpT/a7gIckHaO4jHqPpHco\nT34ioiU9tgEbKC4v1zV/LQr6DmCKpMmSBgKLKZYOyNVGYGlqLwU+quhfLGmQpMnAFIrlElqBM5Jm\np0+3H6t4zVUtjfcN4EBcWBYCSjAHksakM3MkDQbmAQcpQXaAiFgeEeMjYhLF3+kvImIJJckvaaik\n4R1tiiXF91Hv/DX6NHgBxR0QR4AVtXjPGuVaC7QC/1Bc+3oCGAV8DhwCtgAjK45fkeagmYpPsoGZ\n6Q/DEeBV0he+rvYNmENxHXEvsDttC8owB8DtFAvW7U3jfj71Z5+9i7mYy4W7XEqRn+KuvT1p299R\n1+qd398UNTPLhL8pamaWCRd0M7NMuKCbmWXCBd3MLBMu6GZmmXBBNzPLhAu6mVkmXNDNzDLxHzCV\n97hkkUytAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe0b46141d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8VXFRELLbMYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe0dfbe3860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_value = []\n",
    "train_accuracy = []\n",
    "tests_accuracy = []\n",
    "grad = []\n",
    "\n",
    "for i in range(iters):\n",
    "    train_i = np.random.randint(len(data_x_a))\n",
    "    tests_i = np.random.randint(len(data_x_t))\n",
    "    y_predict = module.forward(data_x[ind])\n",
    "    #loss_value_i.append(loss.forward(y_predict, data_y_a[ind]))\n",
    "    module.backward(data_x[ind], loss.backward(y_predict, data_y_a[ind]))\n",
    "    \n",
    "    loss_value_i = []\n",
    "    accuracy_a_i = 0\n",
    "    for x, y in zip(data_x_a, data_y_a):\n",
    "        yp = module.forward(x)\n",
    "        if y > 0 and yp > 0 or y < 0 and yp < 0:\n",
    "            accuracy_a_i += 1\n",
    "        loss_value_i.append(loss.forward(yp, y))\n",
    "        \n",
    "    accuracy_t_i = 0\n",
    "    for x, y in zip(data_x_t, data_y_t):\n",
    "        yp = module.forward(x)\n",
    "        if y > 0 and yp > 0 or y < 0 and yp < 0:\n",
    "            accuracy_t_i += 1\n",
    "            \n",
    "    loss_value.append(np.mean(loss_value_i))\n",
    "    train_accuracy.append(np.mean(accuracy_a_i/len(data_x_a)))\n",
    "    tests_accuracy.append(np.mean(accuracy_t_i/len(data_x_t)))\n",
    "    grad.append(module.G)\n",
    "        \n",
    "\n",
    "plt.plot(loss_value, 'b')\n",
    "plt.plot(train_accuracy, 'r')\n",
    "plt.plot(tests_accuracy, 'g')\n",
    "plt.show()\n",
    "plt.plot(grad)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''m2 = Module(3, 1)\n",
    "\n",
    "while(True):\n",
    "    (x,y) <- uniform(1,N)\n",
    "    ŷ = m1.forward(x)\n",
    "    ŷ2 = m2.forward(ŷ)\n",
    "    em = loss.backward(ŷ,y)\n",
    "    de = loss.backward(ŷ2,y)\n",
    "    m2.backward_update_gradient(ŷ, de)\n",
    "    deprim = m2.bakward(ŷ,de)\n",
    "    m1.backward_update_gradient(x, deprim)\n",
    "    deprim2 = m2.backward(x, deprim)\n",
    "    m1.updateParams(e)\n",
    "    m2.updateParams(e)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "* chaine modules (256) linéaire (500) sigmoide (500) linéaire (10) sigmoide (10) Delta pour classification chiffres numérisés nmist (mapsi ou arf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  4,  9, 16])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,3,4])\n",
    "a*a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_x_a, data_y_a = load_mnist(\"USPS/USPS_train.txt\")\n",
    "size_a = data_x_a.shape[0]\n",
    "\n",
    "data_x_t, data_y_t = load_mnist(\"USPS/USPS_test.txt\")\n",
    "size_t = data_x_t.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dim = [256, 500, 500, 10, 10]\n",
    "iters = 500\n",
    "ggap = 1e-5\n",
    "modules = [LinearModule(dim[0], dim[1], ggap, )]\n",
    "loss = SquareLoss(out_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_value = []\n",
    "train_accuracy = []\n",
    "tests_accuracy = []\n",
    "grad = []\n",
    "\n",
    "for i in range(iters):\n",
    "    train_i = np.random.randint(len(data_x_a))\n",
    "    tests_i = np.random.randint(len(data_x_t))\n",
    "    y_predict = module.forward(data_x[ind])\n",
    "    #loss_value_i.append(loss.forward(y_predict, data_y_a[ind]))\n",
    "    module.backward(data_x[ind], loss.backward(y_predict, data_y_a[ind]))\n",
    "    \n",
    "    loss_value_i = []\n",
    "    accuracy_a_i = 0\n",
    "    for x, y in zip(data_x_a, data_y_a):\n",
    "        yp = module.forward(x)\n",
    "        if y > 0 and yp > 0 or y < 0 and yp < 0:\n",
    "            accuracy_a_i += 1\n",
    "        loss_value_i.append(loss.forward(yp, y))\n",
    "        \n",
    "    accuracy_t_i = 0\n",
    "    for x, y in zip(data_x_t, data_y_t):\n",
    "        yp = module.forward(x)\n",
    "        if y > 0 and yp > 0 or y < 0 and yp < 0:\n",
    "            accuracy_t_i += 1\n",
    "            \n",
    "    loss_value.append(np.mean(loss_value_i))\n",
    "    train_accuracy.append(np.mean(accuracy_a_i/len(data_x_a)))\n",
    "    tests_accuracy.append(np.mean(accuracy_t_i/len(data_x_t)))\n",
    "    grad.append(module.G)\n",
    "        \n",
    "\n",
    "plt.plot(loss_value, 'b')\n",
    "plt.plot(train_accuracy, 'r')\n",
    "plt.plot(tests_accuracy, 'g')\n",
    "plt.show()\n",
    "plt.plot(grad)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
